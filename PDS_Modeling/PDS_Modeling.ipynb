{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a comprehensive list of essential steps to build data science solutions based on CRISP-DM methodology.\n",
    "\n",
    "<img src=\"images/crisp-dm.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Ecosystem for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:13.327418Z",
     "start_time": "2019-10-09T04:12:13.323611Z"
    }
   },
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.284784Z",
     "start_time": "2019-10-09T04:12:13.337818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.7\n",
      "scipy version: 1.3.0\n",
      "numpy version: 1.16.4\n",
      "matplotlib version: 3.1.1\n",
      "pandas version: 0.25.0\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy\n",
    "import matplotlib\n",
    "import pandas\n",
    "\n",
    "!python --version\n",
    "print('scipy version: %s'%(scipy.__version__))\n",
    "print('numpy version: %s'%(numpy.__version__))\n",
    "print('matplotlib version: %s'%(matplotlib.__version__))\n",
    "print('pandas version: %s'%(pandas.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crash Course in Python and SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.296974Z",
     "start_time": "2019-10-09T04:12:14.289011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "11\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "# Strings \n",
    "data = 'hello world' \n",
    "print(data[0]) \n",
    "print(len(data)) \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.310753Z",
     "start_time": "2019-10-09T04:12:14.303406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123.1\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Numbers \n",
    "value = 123.1\n",
    "print(value) \n",
    "value = 10 \n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.323419Z",
     "start_time": "2019-10-09T04:12:14.317242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "# Boolean \n",
    "a = True \n",
    "b = False \n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.332454Z",
     "start_time": "2019-10-09T04:12:14.326486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "# Multiple Assignment \n",
    "a, b, c = 1, 2, 3 \n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.343303Z",
     "start_time": "2019-10-09T04:12:14.335898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# No value \n",
    "a = None \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.352799Z",
     "start_time": "2019-10-09T04:12:14.346570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That is fast\n"
     ]
    }
   ],
   "source": [
    "# If-Then-Else Conditional\n",
    "value = 99 \n",
    "if value == 99: \n",
    "    print('That is fast')\n",
    "elif value > 200: \n",
    "    print('That is too fast' )\n",
    "else:\n",
    "    print('That is safe' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.372105Z",
     "start_time": "2019-10-09T04:12:14.359096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# For-Loop \n",
    "for i in range(10): \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.389170Z",
     "start_time": "2019-10-09T04:12:14.378827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# While-Loop \n",
    "i = 0 \n",
    "while i < 10: \n",
    "    print(i) \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.399703Z",
     "start_time": "2019-10-09T04:12:14.393255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# Tuple\n",
    "a = (1, 2, 3) \n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.415760Z",
     "start_time": "2019-10-09T04:12:14.403067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeroth Value: 1\n",
      "List Length: 4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# List\n",
    "mylist = [1, 2, 3] \n",
    "print(\"Zeroth Value: %d\" % mylist[0]) \n",
    "mylist.append(4) \n",
    "print(\"List Length: %d\" % len(mylist)) \n",
    "for value in mylist: \n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.430019Z",
     "start_time": "2019-10-09T04:12:14.419134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A value: 1\n",
      "A value: 11\n",
      "Keys: dict_keys([' a', ' b', ' c'])\n",
      "Values: dict_values([11, 2, 3])\n",
      "11\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Dictionary\n",
    "mydict = {' a' : 1, ' b' : 2, ' c' : 3} \n",
    "print(\"A value: %d\" % mydict[' a' ]) \n",
    "mydict[' a' ] = 11 \n",
    "print(\"A value: %d\" % mydict[' a' ]) \n",
    "print(\"Keys: %s\" % mydict.keys()) \n",
    "print(\"Values: %s\" % mydict.values()) \n",
    "for key in mydict.keys(): \n",
    "    print(mydict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.440603Z",
     "start_time": "2019-10-09T04:12:14.434437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Sum function \n",
    "def mysum(x, y): \n",
    "    return x + y\n",
    "\n",
    "# Test sum function \n",
    "result = mysum(1, 3) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.454115Z",
     "start_time": "2019-10-09T04:12:14.444526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# define an array \n",
    "import numpy \n",
    "mylist = [1, 2, 3] \n",
    "myarray = numpy.array(mylist) \n",
    "print(myarray) \n",
    "print(myarray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.471556Z",
     "start_time": "2019-10-09T04:12:14.457778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [3 4 5]]\n",
      "(2, 3)\n",
      "First row: [1 2 3]\n",
      "Last row: [3 4 5]\n",
      "Specific row and col: 3\n",
      "Whole col: [3 5]\n"
     ]
    }
   ],
   "source": [
    "# access values \n",
    "import numpy \n",
    "mylist = [[1, 2, 3], [3, 4, 5]] \n",
    "myarray = numpy.array(mylist) \n",
    "print(myarray) \n",
    "print(myarray.shape) \n",
    "print(\"First row: %s\" % myarray[0]) \n",
    "print(\"Last row: %s\" % myarray[-1]) \n",
    "print(\"Specific row and col: %s\" % myarray[0, 2]) \n",
    "print(\"Whole col: %s\" % myarray[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.488864Z",
     "start_time": "2019-10-09T04:12:14.478711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition: [5 5 5]\n",
      "Multiplication: [6 6 6]\n"
     ]
    }
   ],
   "source": [
    "# arithmetic \n",
    "import numpy \n",
    "myarray1 = numpy.array([2, 2, 2]) \n",
    "myarray2 = numpy.array([3, 3, 3]) \n",
    "print(\"Addition: %s\" % (myarray1 + myarray2)) \n",
    "print(\"Multiplication: %s\" % (myarray1 * myarray2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:14.795582Z",
     "start_time": "2019-10-09T04:12:14.493881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# basic line plot \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy \n",
    "myarray = numpy.array([1, 2, 3]) \n",
    "plt.plot(myarray) \n",
    "plt.xlabel(' some x axis' ) \n",
    "plt.ylabel(' some y axis' ) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:15.197353Z",
     "start_time": "2019-10-09T04:12:14.798148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAZH0lEQVR4nO3dfZQd9X3f8fcHIZcNBja21gZWGNkpJTEQkLoWYKUcHlKeHSglCakNBSfVgUNycE5CavmkpLabih5a1zzEqDI2gRQ79QlCphQMNBgDdYW9ekI8mEYhuAjRsBAkQdDBSP70j5m1r67uamfFzr27O5/XOffcefjdO18Nw/3snZn7+8k2ERHRXPv0uoCIiOitBEFERMMlCCIiGi5BEBHRcAmCiIiG27fXBUzUnDlzPG/evF6XERExraxevfoV2wOd1k27IJg3bx7Dw8O9LiMiYlqR9MOx1uXUUEREwyUIIiIaLkEQEdFwCYKIiIZLEERENFyCICKi4Wq9fVRSP3ALcDRg4JO2/3fLegHXA2cDbwKX2l5TZ00REdPFyrUvct39z7J5y3YO7e/j6jOO5Pz5g5O+nbp/R3A98C3bF0p6F/AzbevPAo4oH8cDN5fPERGNtnLtiyxZsYHtb+8E4MUt21myYgPApIdBbaeGJB0InAR8BcD2j2xvaWt2HnC7C6uAfkmH1FVTRMR0cd39z/4kBEZtf3sn193/7KRvq85rBB8CRoBbJa2VdIuk/dvaDAIvtMxvKpftQtJiScOShkdGRuqrOCJiiti8ZfuElr8TdQbBvsAC4Gbb84G/Bz7d1kYdXrfbkGm2l9sesj00MNCxq4yIiBnl0P6+CS1/J+oMgk3AJtuPl/N/QREM7W0Oa5mfC2yusaaIiGnh6jOOpG/2rF2W9c2exdVnHDnp26otCGz/P+AFSaNVnwY83dbsbuASFU4Attp+qa6aIiKmi/PnD7L0gmMY7O9DwGB/H0svOGZa3jX0O8Ad5R1DzwGXSbocwPYy4F6KW0c3Utw+elnN9URETBvnzx+s5YO/Xa1BYHsdMNS2eFnLegNX1llDRETsWX5ZHBHRcAmCiIiGSxBERDRcgiAiouESBBERDZcgiIhouARBRETDJQgiIhouQRAR0XAJgoiIhksQREQ0XIIgIqLhEgQREQ2XIIiIaLgEQUREw9U6HoGk54HXgZ3ADttDbetPBr4J/E25aIXtz9VZU0RE7KruEcoATrH9yh7WP2r73C7UERERHeTUUEREw9UdBAYekLRa0uIx2pwoab2k+yQd1amBpMWShiUNj4yM1FdtREQD1X1qaJHtzZLeBzwo6Qe2H2lZvwY43PYbks4GVgJHtL+J7eXAcoChoSHXXHNERKPU+o3A9uby+WXgLmBh2/pttt8op+8FZkuaU2dNERGxq9qCQNL+kg4YnQZOB55sa3OwJJXTC8t6Xq2rpoiI2F2dp4beD9xVfs7vC3zN9rckXQ5gexlwIXCFpB3AduAi2zn1ExHRRbUFge3ngGM7LF/WMn0TcFNdNURExPhy+2hERMMlCCIiGi5BEBHRcAmCiIiGSxBERDRcgiAiouESBBERDZcgiIhouARBRETDJQgiIhouQRAR0XAJgoiIhksQREQ0XIIgIqLhEgQREQ2XIIiIaLhag0DS85I2SFonabjDekm6QdJGSU9IWlBnPRERsbs6h6ocdYrtV8ZYdxZwRPk4Hri5fI6IiC7p9amh84DbXVgF9Es6pMc1RUQ0St1BYOABSaslLe6wfhB4oWV+U7lsF5IWSxqWNDwyMlJTqRERzVR3ECyyvYDiFNCVkk5qW68Or/FuC+zltodsDw0MDNRRZ0REY9UaBLY3l88vA3cBC9uabAIOa5mfC2yus6aIiNhVbUEgaX9JB4xOA6cDT7Y1uxu4pLx76ARgq+2X6qopIiJ2V+ddQ+8H7pI0up2v2f6WpMsBbC8D7gXOBjYCbwKX1VhPRER0UFsQ2H4OOLbD8mUt0waurKuGiIgYX69vH42IiB5LEERENFyCICKi4RIEERENlyCIiGi4BEFERMMlCCIiGi5BEBHRcAmCiIiGSxBERDRcgiAiouESBBERDZcgiIhouARBRETDjRsEkq6SdGA5eMxXJK2RdHo3iouIiPpV+UbwSdvbKEYYG6AYPObaqhuQNEvSWkn3dFh3sqStktaVj2sqVx4REZOiysA0owPMnw3canu9ymHHKroKeAY4cIz1j9o+dwLvFxERk6jKN4LVkh6gCIL7y3GIf1zlzSXNBc4Bbtn7EiMiok5VguA3gU8DH7H9JvAuqo8t/EXgD9hzcJwoab2k+yQdVfF9IyJikowZBJJ+vpw8rnz+kKQFwOFUOKUk6VzgZdur99BsDXC47WOBG4GVY7zXYknDkoZHRkbG23REREyAivHjO6yQltteLOnbHVbb9ql7fGNpKXAxsAPYj+IawQrbn9jDa54Hhmy/MlaboaEhDw8P72nTERHRRtJq20Od1o35l73txeXzKXuzUdtLgCVlAScDv98eApIOBv7WtiUtpPiG8urebC8iIvZOld8RfF7SrJb5AyXdurcblHS5pMvL2QuBJyWtB24ALvJYX1EiIqIWVW4f3Rf4nqTLgIMpzuXfOJGN2H4YeLicXtay/Cbgpom8V0RETK5xg8D2Ekl/CTwOvAacZHtj7ZVFRERXVDk1dBJwPfA5ir/qb5J0aM11RUREl1Q5NfQfgV+1/TSApAuAh4Cf3+OrIiJiWqgSBCfa3jk6Y3uFpO/UWFNERHRRlWsEOyWdAxxF8XuAUZ+rraqIiOiaKtcIlgG/DvwORQd0v0rx6+KIiJgBqvQ19FHblwCv2f4scCJwWL1lRUREt1QJgu3l85vl3UJvAx+sr6SIiOimKheL75HUD1xH0UmcgS/XWlVERHRNlYvFny8n7yxHGdvP9tZ6y4qIiG6p8o3gJ2y/BbxVUy0REdEDVa4RRETEDJYgiIhouCq/I7hT0jmSEhoRETNQlQ/3m4F/AfyVpGtbhrCMiIgZYNwgsP0/bX8cWAA8Dzwo6buSLpM0u+4CIyKiXpVO90h6L3Ap8FvAWopuqRcAD1Z47SxJa8tbT9vXSdINkjZKekLSgglVHzFFrFz7IouufYgPfvp/sOjah1i59sVelxRR2bi3j0paQdHl9J8BH7P9Urnqv0mqMor8VcAzFIPXtzsLOKJ8HE9xGur4Cu8ZMWWsXPsiS1ZsYPvbRSe9L27ZzpIVGwA4f/5gL0uLqKTKN4KbbH/Y9tKWEADA9tCeXihpLnAOcMsYTc4DbndhFdAv6ZAqhUdMFdfd/+xPQmDU9rd3ct39z/aoooiJqXKN4KF38P5fBP4A+PEY6weBF1rmN5XLdiFpsaRhScMjIyPvoJyIybd5y/YJLY+Yamq7JVTSucDLtlfvqVmHZd5tgb3c9pDtoYGBgUmrMWIyHNrfN6HlEVNNnb8NWAT8iqTngT8HTpX0X9vabGLXLq3nAptrrCli0l19xpH0zZ61y7K+2bO4+owje1RRxMRU+UGZJH1C0jXl/AckLRzvdbaX2J5rex5wEfCQ7U+0NbsbuKTcxgnA1vbrEBFT3fnzB1l6wTEM9vchYLC/j6UXHJMLxTFtVOl07ksU5/hPpRie8nXgTuAje7NBSZcD2F4G3AucDWwE3gQu25v3jOi18+cP5oM/pq0qQXC87QWS1gLYfk3SuyayEdsPAw+X08talhu4ciLvFRERk6vKNYK3Jc2ivIgraYCx7wKKiIhppkoQ3ADcBbxP0h8DjwH/vtaqIiKia6qMUHaHpNXAaRS3e55v+5naK4uIiK6oOkLZ3wKPlu37JC2wvaa+siIioluq9DX0eYoO5/6an/7YyxR3EUVExDRX5RvBrwE/Z/tHdRcTERHdV+Vi8ZNAf92FREREb1T5RrAUWCvpSeCt0YW2f6W2qiIiomuqBMFtwH8ANpDfD0REzDhVguAV2zfUXklERPRElSBYLWkpRQdxraeGcvtoRMQMUCUI5pfPJ7Qsy+2jEREzRJVfFp/SjUIiIqI3qoxHcJCkL4wOFSnpP0k6qBvFRURE/ar8juCrFGMQ/Fr52AbcWmdRERHRPVWuEfyc7X/eMv9ZSevGe5Gk/YBHgH9QbucvbP9RW5uTgW8Cf1MuWmH7c1UKj4iIyVElCLZL+iXbjwFIWgRsr/C6t4BTbb8haTbwmKT7bK9qa/eo7XMnVnZEREyWKkFwBXBbeV1AwN9RdEK3R+XoY2+Us7PLh8d+RURE9EKVu4bWAcdKOrCc31b1zcuRzVYD/xD4E9uPd2h2oqT1wGbg920/VfX9IyLinaty19BVZQi8DnxB0hpJp1d5c9s7bR8HzAUWSjq6rcka4HDbxwI3AivHqGHx6F1LIyMjVTYdEREVVblr6JPlt4DTgfcBlwHXTmQjtrdQDF5/ZtvybbbfKKfvBWZLmtPh9cttD9keGhgYmMimIyJiHFWCQOXz2cCttte3LBv7RdKApP5yug/4ZeAHbW0OlqRyemFZz6vVy4+IiHeqal9DDwAfBJZIOoBqvZAeQnGReRbFB/w3bN8j6XIA28uAC4ErJO2guBPpovIic0REdInG+9yVtA9wHPCc7S2S3gsM2n6iGwW2Gxoa8vDwcC82HRExbUlabXuo07oqdw39mOKi7uj8q+T0TUTEjFHlGkFERMxgCYKIiIZLEERENFyCICKi4RIEERENlyCIiGi4BEFERMMlCCIiGi5BEBHRcAmCiIiGSxBERDRcgiAiouESBBERDZcgiIhouARBRETD1RYEkvaT9D1J6yU9JemzHdpI0g2SNkp6QtKCuuqJiIjOqgxVubfeAk61/Yak2cBjku6zvaqlzVnAEeXjeODm8jkiIrqktm8ELrxRzs4uH+3jYp4H3F62XQX0SzqkrpoiImJ3tV4jkDRL0jrgZeBB24+3NRkEXmiZ31Qua3+fxZKGJQ2PjIzUV3BERAPVGgS2d9o+DpgLLJR0dFsTdXpZh/dZbnvI9tDAwEAdpUZENFZX7hqyvQV4GDizbdUm4LCW+bnA5m7UFBERhTrvGhqQ1F9O9wG/DPygrdndwCXl3UMnAFttv1RXTRERsbs67xo6BLhN0iyKwPmG7XskXQ5gexlwL3A2sBF4E7isxnoiIqKD2oLA9hPA/A7Ll7VMG7iyrhoiImJ8+WVxRETDJQgiIhouQRAR0XAJgoiIhksQREQ0XIIgIqLhEgQREQ2XIIiIaLgEQUREwyUIIiIaLkEQEdFwCYKIiIZLEERENFyCICKi4RIEERENlyCIiGi4OoeqPEzStyU9I+kpSVd1aHOypK2S1pWPa+qqJyIiOqtzqModwO/ZXiPpAGC1pAdtP93W7lHb59ZYR0RE7EFt3whsv2R7TTn9OvAMMFjX9iIiYu905RqBpHkU4xc/3mH1iZLWS7pP0lFjvH6xpGFJwyMjIzVWGhHRPLUHgaR3A3cCn7K9rW31GuBw28cCNwIrO72H7eW2h2wPDQwM1FtwRETD1BoEkmZThMAdtle0r7e9zfYb5fS9wGxJc+qsKSIidlXnXUMCvgI8Y/sLY7Q5uGyHpIVlPa/WVVNEROyuzruGFgEXAxskrSuXfQb4AIDtZcCFwBWSdgDbgYtsu8aaIiKiTW1BYPsxQOO0uQm4qa4aIiJifPllcUREwyUIIiIaLkEQEdFwCYKIiIZLEERENFyCICKi4RIEERENlyCIiGi4BEFERMMlCCIiGi5BEBHRcAmCiIiGSxBERDRcgiAiouESBBERDVfbeASSDgNuBw4Gfgwst319WxsB1wNnA28Cl9peU1dNK9e+yHX3P8vmLds5tL+Pq884kvPnD9a1uYiIaaHOEcp2AL9ne42kA4DVkh60/XRLm7OAI8rH8cDN5fOkW7n2RZas2MD2t3cC8OKW7SxZsQEgYRARjVbbqSHbL43+dW/7deAZoP0T9zzgdhdWAf2SDqmjnuvuf/YnITBq+9s7ue7+Z+vYXETEtNGVawSS5gHzgcfbVg0CL7TMb2L3sEDSYknDkoZHRkb2qobNW7ZPaHlERFPUHgSS3g3cCXzK9rb21R1estvg9baX2x6yPTQwMLBXdRza3zeh5RERTVFrEEiaTRECd9he0aHJJuCwlvm5wOY6arn6jCPpmz1rl2V9s2dx9RlH1rG5iIhpo7YgKO8I+grwjO0vjNHsbuASFU4Attp+qY56zp8/yNILjmGwvw8Bg/19LL3gmFwojojGq/OuoUXAxcAGSevKZZ8BPgBgexlwL8Wtoxspbh+9rMZ6OH/+YD74IyLa1BYEth+j8zWA1jYGrqyrhoiIGF9+WRwR0XAJgoiIhksQREQ0XIIgIqLhEgQREQ2n4sad6UPSCPDDd/g2c4BXJqGcyTQVa4LUNVFTsa6pWBOkromYjJoOt92xa4ZpFwSTQdKw7aFe19FqKtYEqWuipmJdU7EmSF0TUXdNOTUUEdFwCYKIiIZrahAs73UBHUzFmiB1TdRUrGsq1gSpayJqramR1wgiIuKnmvqNICIiSgmCiIiGm1FBIOmrkl6W9OQY6yXpBkkbJT0haUHLujMlPVuu+3QXa/p4WcsTkr4r6diWdc9L2iBpnaThyaqpYl0nS9pabnudpGta1tWyryrWdXVLTU9K2inpPeW6WvaXpMMkfVvSM5KeknRVhza9OLaq1NX146tiXV09virW1Itjaz9J35O0vqzrsx3a1H9s2Z4xD+AkYAHw5Bjrzwbuo+ge+wTg8XL5LOCvgQ8B7wLWAx/uUk0fBX62nD5rtKZy/nlgTo/21cnAPR2W17avqtTV1vZjwEN17y/gEGBBOX0A8H/a/809Oraq1NX146tiXV09vqrU1KNjS8C7y+nZFOO6n9DtY2tGfSOw/Qjwd3toch5wuwurgH5JhwALgY22n7P9I+DPy7a112T7u7ZfK2dXUQzXWbsK+2oste2rvajrN4CvT9a2x2L7JdtryunXgWeA9hGOenFsjVtXL46vivtrLLXsr72oqVvHlm2/Uc7OLh/td/DUfmzNqCCoYBB4oWV+U7lsrOXd9psUyT/KwAOSVkta3IN6Tiy/st4n6ahy2ZTYV5J+BjiTYkzsUbXvL0nzgPkUf7m16umxtYe6WnX9+Bqnrp4cX+Ptq24fW5JmqRjF8WXgQdtdP7bqHKpyKuo0Ypr3sLxrJJ1C8T/qL7UsXmR7s6T3AQ9K+kH5F3M3rKHom+QNSWcDK4EjmAL7qvQx4H/Zbv32UOv+kvRuig+HT9ne1r66w0u6cmyNU9dom64fX+PU1ZPjq8q+osvHlu2dwHGS+oG7JB1tu/UaWe3HVtO+EWwCDmuZnwts3sPyrpD0i8AtwHm2Xx1dbntz+fwycBfFV8GusL1t9Cur7XuB2ZLm0ON91eIi2r6617m/JM2m+AC5w/aKDk16cmxVqKsnx9d4dfXi+Kqyr0pdPbZatrEFeJji20ir+o+tybroMVUewDzGvgB6DrtedPleuXxf4Dngg/z0ostRXarpA8BG4KNty/cHDmiZ/i5wZhf31cH89AeHC4H/W+63WvfVeHWV6w+iuI6wfzf2V/nvvh344h7adP3YqlhX14+vinV19fiqUlOPjq0BoL+c7gMeBc7t9rE1o04NSfo6xd0IcyRtAv6I4uILtpcB91Jcgd8IvAlcVq7bIem3gfsprsR/1fZTXarpGuC9wJckAexw0cvg+ym+JkLxH/xrtr81GTVVrOtC4ApJO4DtwEUujr7a9lXFugD+GfCA7b9veWmd+2sRcDGwoTyXC/AZig/Znh1bFevqxfFVpa5uH19VaoLuH1uHALdJmkVxhuYbtu+RdHlLXbUfW+liIiKi4Zp2jSAiItokCCIiGi5BEBHRcAmCiIiGSxBERDRcgiBimpB0i6QP97qOmHly+2hERMPlG0HMWGVnXn9a9i2/QdLvlsuPk7Sq7Nv9Lkk/Wy5/WNJ/lvRI2W/9RyStkPRXkv5dy/t+ouxDfp2k/1L+GKh1uweVfcQfWc5/XdK/6lDfNZK+X9a3vOx3ft9y2cllm6WS/rilvqGx/l0ReytBEDPZccCg7aNtHwPcWi6/HfjXtn8R2EDx6+VRP7J9ErAM+CZwJXA0cKmk90r6BeDXKTohOw7YCXy8daO2twK/DfyppIsoxgP4cof6brL9EdtHU3QvcK7tHcClwM2S/ilFvzPtg5WM9e+K2CsJgpjJngM+JOlGSWcC2yQdRNG3y3fKNrdRDIYz6u7yeQPwlIt+7N8q3+sw4DTgHwPfL7sqOI1iYJBd2H6wfI8/AX5rjPpOkfS4pA3AqcBR5WufAv4M+O/AJ130Nb/Hf1fF/RHRUYIgZiwXA7IcS9Gj45UUPXCO563y+cct06Pz+1J0/HWb7ePKx5G2/237m0jaB/gFin503tNh/X7Al4ALy7/qvwzs19LkGGALRT83k/HvihhTgiBmrLJb431s3wn8G4qhCrcCr0n6J2Wzi4HvjPUeHfwlcGHZLz2S3iPp8A7tfpdiFKzfAL5adoHcavRD/5Wyj/wLW+q+gKKjuJOAG8p+6vf475pA/RG7mVG9j0a0GQRuLf86B1hSPv9LYJmKkaieo+zNsQrbT0v6Q4rRqvYB3qb4q/yHo20k/SOK00ELbb8u6RHgD2m5FmF7i6QvU5w+eh74fvnaOcC1wGm2X5B0E3B9WfN4/66IvZLbRyMiGi6nhiIiGi5BEBHRcAmCiIiGSxBERDRcgiAiouESBBERDZcgiIhouP8PZAO3FDZkylsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# basic scatter plot \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy \n",
    "x = numpy.array([1, 2, 3]) \n",
    "y = numpy.array([2, 4, 6]) \n",
    "plt.scatter(x,y) \n",
    "plt.xlabel(' some x axis' ) \n",
    "plt.ylabel(' some y axis' ) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:15.221264Z",
     "start_time": "2019-10-09T04:12:15.201164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a    1\n",
      " b    2\n",
      " c    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# series\n",
    "import numpy \n",
    "import pandas \n",
    "myarray = numpy.array([1, 2, 3]) \n",
    "rownames = [' a' , ' b' , ' c' ] \n",
    "myseries = pandas.Series(myarray, index=rownames)\n",
    "print(myseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:15.235381Z",
     "start_time": "2019-10-09T04:12:15.227354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(myseries[0]) \n",
    "print(myseries[' a' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:15.257653Z",
     "start_time": "2019-10-09T04:12:15.240602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two  three\n",
      "a    1    2      3\n",
      "b    4    5      6\n"
     ]
    }
   ],
   "source": [
    "# dataframe\n",
    "import numpy \n",
    "import pandas \n",
    "myarray = numpy.array([[1, 2, 3], [4, 5, 6]]) \n",
    "rownames = ['a' , 'b' ] \n",
    "colnames = ['one' , 'two' , 'three' ] \n",
    "mydataframe = pandas.DataFrame(myarray, index=rownames, columns=colnames) \n",
    "print(mydataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:15.278457Z",
     "start_time": "2019-10-09T04:12:15.261069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method 1:\n",
      "one column:\n",
      "a    1\n",
      "b    4\n",
      "Name: one, dtype: int64\n",
      "method 2:\n",
      "one column:\n",
      "a    1\n",
      "b    4\n",
      "Name: one, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"method 1:\") \n",
    "print(\"one column:\\n%s\" % mydataframe['one']) \n",
    "print(\"method 2:\") \n",
    "print(\"one column:\\n%s\" % mydataframe.one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How To Load Machine Learning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:15.310222Z",
     "start_time": "2019-10-09T04:12:15.287395Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0b35de63e2a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQUOTE_NONE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: "
     ]
    }
   ],
   "source": [
    "# Load CSV Using Python Standard Library \n",
    "import csv \n",
    "import numpy \n",
    "filename = 'breast_cancer_data.csv' \n",
    "raw_data = open(filename, 'rt' ) \n",
    "reader = csv.reader(raw_data, delimiter=',' , quoting=csv.QUOTE_NONE) \n",
    "x = list(reader) \n",
    "data = numpy.array(x).astype('float' ) \n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:15.341951Z",
     "start_time": "2019-10-09T04:12:15.315859Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-327499ca09f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'breast_cancer_data.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mraw_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[0;32m   1139\u001b[0m         \u001b[1;31m# converting the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1141\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1142\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(chunk_size)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m             \u001b[1;31m# Convert each value according to its column and store\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m             \u001b[1;31m# Convert each value according to its column and store\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    773\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'0x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: "
     ]
    }
   ],
   "source": [
    "# Load CSV using NumPy \n",
    "from numpy import loadtxt \n",
    "filename = 'breast_cancer_data.csv' \n",
    "raw_data = open(filename, 'rt' ) \n",
    "data = loadtxt(raw_data, delimiter=\",\") \n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:18.194899Z",
     "start_time": "2019-10-09T04:12:15.348909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load CSV from URL using NumPy \n",
    "from numpy import loadtxt \n",
    "from urllib.request import urlopen \n",
    "url = 'https://goo.gl/bDdBiA' \n",
    "raw_data = urlopen(url) \n",
    "dataset = loadtxt(raw_data, delimiter=\",\") \n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:18.214996Z",
     "start_time": "2019-10-09T04:12:18.198266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 11)\n"
     ]
    }
   ],
   "source": [
    "# Load CSV using Pandas \n",
    "from urllib.request import urlopen\n",
    "from pandas import read_csv \n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "data = read_csv(filename, names=names) \n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:21.241627Z",
     "start_time": "2019-10-09T04:12:18.218153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load CSV using Pandas from URL \n",
    "from pandas import read_csv \n",
    "url = 'https://goo.gl/bDdBiA' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "data = read_csv(url, names=names) \n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Your Data With Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:21.272463Z",
     "start_time": "2019-10-09T04:12:21.245821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Row  Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
      "0    NaN  Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape   \n",
      "1    0.0                5                        1                         1   \n",
      "2    1.0                5                        4                         4   \n",
      "3    2.0                3                        1                         1   \n",
      "4    3.0                6                        8                         8   \n",
      "5    4.0                4                        1                         1   \n",
      "6    5.0                8                       10                        10   \n",
      "7    6.0                1                        1                         1   \n",
      "8    7.0                2                        1                         2   \n",
      "9    8.0                2                        1                         1   \n",
      "10   9.0                4                        2                         1   \n",
      "11  10.0                1                        1                         1   \n",
      "12  11.0                2                        1                         1   \n",
      "13  12.0                5                        3                         3   \n",
      "14  13.0                1                        1                         1   \n",
      "15  14.0                8                        7                         5   \n",
      "16  15.0                7                        4                         6   \n",
      "17  16.0                4                        1                         1   \n",
      "18  17.0                4                        1                         1   \n",
      "19  18.0               10                        7                         7   \n",
      "\n",
      "      Marginal Adhesion  Single Epithelial  Cell Size  Bare Nuclei  \\\n",
      "0   Marginal Adhesion    Single Epithelial  Cell Size  Bare Nuclei   \n",
      "1                     1                             2            1   \n",
      "2                     5                             7           10   \n",
      "3                     1                             2            2   \n",
      "4                     1                             3            4   \n",
      "5                     3                             2            1   \n",
      "6                     8                             7           10   \n",
      "7                     1                             2           10   \n",
      "8                     1                             2            1   \n",
      "9                     1                             2            1   \n",
      "10                    1                             2            1   \n",
      "11                    1                             1            1   \n",
      "12                    1                             2            1   \n",
      "13                    3                             2            3   \n",
      "14                    1                             2            3   \n",
      "15                   10                             7            9   \n",
      "16                    4                             6            1   \n",
      "17                    1                             2            1   \n",
      "18                    1                             2            1   \n",
      "19                    6                             4           10   \n",
      "\n",
      "    Bland Chromatin  Normal Nucleoli  Mitoses  Target  \n",
      "0   Bland Chromatin  Normal Nucleoli  Mitoses  Target  \n",
      "1                 3                1        1       0  \n",
      "2                 3                2        1       0  \n",
      "3                 3                1        1       0  \n",
      "4                 3                7        1       0  \n",
      "5                 3                1        1       0  \n",
      "6                 9                7        1       1  \n",
      "7                 3                1        1       0  \n",
      "8                 3                1        1       0  \n",
      "9                 1                1        5       0  \n",
      "10                2                1        1       0  \n",
      "11                3                1        1       0  \n",
      "12                2                1        1       0  \n",
      "13                4                4        1       1  \n",
      "14                3                1        1       0  \n",
      "15                5                5        4       1  \n",
      "16                4                3        1       1  \n",
      "17                2                1        1       0  \n",
      "18                3                1        1       0  \n",
      "19                4                1        2       1  \n"
     ]
    }
   ],
   "source": [
    "# View first 20 rows \n",
    "from pandas import read_csv \n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "data = read_csv(filename, names=names) \n",
    "peek = data.head(20)\n",
    "print(peek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:21.290992Z",
     "start_time": "2019-10-09T04:12:21.275646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 11)\n"
     ]
    }
   ],
   "source": [
    "# Dimensions of your data \n",
    "from pandas import read_csv \n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "data = read_csv(filename, names=names) \n",
    "shape = data.shape \n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:21.315057Z",
     "start_time": "2019-10-09T04:12:21.294776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row                             float64\n",
      "Clump Thickness                  object\n",
      "Uniformity of Cell Size          object\n",
      "Uniformity of Cell Shape         object\n",
      "Marginal Adhesion                object\n",
      "Single Epithelial  Cell Size     object\n",
      "Bare Nuclei                      object\n",
      "Bland Chromatin                  object\n",
      "Normal Nucleoli                  object\n",
      "Mitoses                          object\n",
      "Target                           object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Data Types for Each Attribute \n",
    "from pandas import read_csv \n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "data = read_csv(filename, names=names) \n",
    "types = data.dtypes \n",
    "print(types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian and summary statistics\n",
    "\n",
    "- The Gaussian distribution describes many observations, including many observations seen during applied machine learning.\n",
    "- The central tendency of a distribution is the most likely observation and can be estimated from a sample of data as the mean or median.\n",
    "- The variance is the average deviation from the mean in a distribution and can be estimated from a sample of data as the variance and standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean\n",
    "\n",
    "- The mean of a sample is calculated as the sum of the observations divided by the total number of observations in the sample.\n",
    "\n",
    "![](images/mean.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance\n",
    "\n",
    "- The variance of a distribution refers to how much on average that observations vary or differ from the mean value. \n",
    "- It is useful to think of the variance as a measure of the spread of a distribution. \n",
    "- A low variance will have values grouped around the mean (e.g. a narrow bell shape), whereas a high variance will have values spread out from the mean (e.g. a wide bell shape.)\n",
    "\n",
    "![](images/variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard deviation\n",
    "\n",
    "- It is hard to interpret the variance because the units are the squared units of the observations.\n",
    "- We can return the units to the original units of the observations by taking the square root of the result. - - Often, when the spread of a Gaussian distribution is summarized, it is described using the square root of the variance. This is called the standard deviation. \n",
    "- The standard deviation, along with the mean, are the two key parameters required to specify any Gaussian distribution.\n",
    "\n",
    "![](images/std.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:21.417612Z",
     "start_time": "2019-10-09T04:12:21.320402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Row\n",
      "count  300.000\n",
      "mean   149.500\n",
      "std     86.747\n",
      "min      0.000\n",
      "25%     74.750\n",
      "50%    149.500\n",
      "75%    224.250\n",
      "max    299.000\n"
     ]
    }
   ],
   "source": [
    "# Statistical Summary \n",
    "from pandas import read_csv \n",
    "from pandas import set_option \n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "data = read_csv(filename, names=names) \n",
    "set_option('display.width', 100) \n",
    "set_option('precision', 3) \n",
    "description = data.describe() \n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability\n",
    "\n",
    "- Probability is a measure that quantifies the likelihood that an event will occur. \n",
    "- The probability of an event can be calculated directly by counting all of the occurrences of the event, dividing them by the total possible outcomes of the event.\n",
    "\n",
    "![](images/probability.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint probability, marginal probability, and conditional probability\n",
    "\n",
    "- Joint probability is the probability of two or more events occurring simultaneously.\n",
    "- Marginal probability is the probability of an event irrespective of the outcome of other variables.\n",
    "- Conditional probability is the probability of one event occurring in the presence of one or more other events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:21.441458Z",
     "start_time": "2019-10-09T04:12:21.422921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target\n",
      "0         163\n",
      "1         137\n",
      "Target      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Class Distribution\n",
    "from pandas import read_csv \n",
    "filename = \"pima-indians-diabetes.data.csv\" \n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "class_counts = data.groupby('Target').size() \n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance\n",
    "\n",
    "- In probability, covariance is the measure of the joint probability for two random variables. It describes how the two variables change together. \n",
    "- It is denoted as the function cov(X, Y), where X and Y are the two random variables being considered.\n",
    "\n",
    "![](images/covariance_sample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson's correlation coefficient\n",
    "\n",
    "- The covariance can be normalized to a score between -1 and 1 to make the magnitude interpretable by dividing it by the standard deviation of X and Y. \n",
    "- The result is called the correlation of the variables, also called the Pearson’s correlation coefficient, named for the developer of the method.\n",
    "\n",
    "![](images/pearson.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:21.472828Z",
     "start_time": "2019-10-09T04:12:21.444487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Row\n",
      "Row  1.0\n"
     ]
    }
   ],
   "source": [
    "# Pairwise Pearson correlations \n",
    "from pandas import read_csv \n",
    "from pandas import set_option \n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "data = read_csv(filename, names=names) \n",
    "set_option('display.width', 100) \n",
    "set_option('precision', 3) \n",
    "correlations = data.corr(method='pearson') \n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:21.503036Z",
     "start_time": "2019-10-09T04:12:21.477751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Skew for each attribute \n",
    "from pandas import read_csv \n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "data = read_csv(filename, names=names) \n",
    "skew = data.skew() \n",
    "print(skew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing\n",
    "\n",
    "- A test that assumes that data has a normal distribution.\n",
    "- A test that assumes that two samples were drawn from the same underlying population distribution.\n",
    "\n",
    "Steps (intuition):\n",
    "0. Default action\n",
    "1. Null hypothesis\n",
    "2. Create model\n",
    "3. Do calculation\n",
    "4. Decide (reject or do not reject?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:21.906951Z",
     "start_time": "2019-10-09T04:12:21.506329Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-9d30c9e06254>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Compute p-value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mpearson_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Clump Thickness'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The Pearson correlation coefficient is\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpearson_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"with a p-value of\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36mpearsonr\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   3031\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3033\u001b[1;33m     \u001b[0mmx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3034\u001b[0m     \u001b[0mmy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3035\u001b[0m     \u001b[0mxm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mym\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# Hypothesis testing using Pearson\n",
    "from matplotlib import pyplot \n",
    "from pandas import read_csv \n",
    "import numpy \n",
    "from scipy import stats\n",
    "\n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "data = read_csv(filename, names=names) \n",
    "\n",
    "# Compute p-value\n",
    "pearson_coef, p_value = stats.pearsonr(data['Clump Thickness'], data['Target'])\n",
    "print(\"The Pearson correlation coefficient is\", pearson_coef, \"with a p-value of\", p_value)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:21.931424Z",
     "start_time": "2019-10-09T04:12:21.909539Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['class', 'age'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-4c4f7be63522>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Group the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mgrouped_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Find p-value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[1;32m-> 2934\u001b[1;33m                                                    raise_missing=True)\n\u001b[0m\u001b[0;32m   2935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[0;32m   1353\u001b[0m                           raise_missing}\n\u001b[1;32m-> 1354\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[0;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1244\u001b[0m                 raise KeyError(\n\u001b[0;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1246\u001b[1;33m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['class', 'age'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Hypothesis testing using t-test independent samples (for 2 groups only)\n",
    "from matplotlib import pyplot \n",
    "from pandas import read_csv \n",
    "import numpy \n",
    "from scipy import stats\n",
    "\n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "data = read_csv(filename, names=names) \n",
    "\n",
    "# Group the data\n",
    "grouped_data = data[['class', 'age']].groupby(['class'])\n",
    "\n",
    "# Find p-value\n",
    "t_value, p_value = stats.ttest_ind(grouped_data.get_group(0)['age'], grouped_data.get_group(1)['age'])  \n",
    "print(\"The t-value is\", t_value, \"with a p-value of\", p_value)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:21.957062Z",
     "start_time": "2019-10-09T04:12:21.933867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f-value is 46.14061123873557 with a p-value of 2.2099754606650332e-11\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis testing using ANOVA (note: for more than 2 groups)\n",
    "from matplotlib import pyplot \n",
    "from pandas import read_csv \n",
    "import numpy \n",
    "from scipy import stats\n",
    "\n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "data = read_csv(filename, names=names) \n",
    "\n",
    "# Group the data\n",
    "grouped_data = data[['class', 'age']].groupby(['class'])\n",
    "\n",
    "# Find p-value\n",
    "f_value, p_value = stats.f_oneway(grouped_data.get_group(0)['age'], grouped_data.get_group(1)['age'])  \n",
    "print(\"The f-value is\", f_value, \"with a p-value of\", p_value)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:22.195980Z",
     "start_time": "2019-10-09T04:12:21.959236Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Clump Thickness'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-30569295f377>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mbinarizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mbinary_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinarizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mbinary_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1855\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1856\u001b[0m         \"\"\"\n\u001b[1;32m-> 1857\u001b[1;33m         \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1858\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Clump Thickness'"
     ]
    }
   ],
   "source": [
    "# Hypothesis testing using chi-square test (Note: code is not good)\n",
    "from matplotlib import pyplot \n",
    "from pandas import read_csv \n",
    "import numpy \n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import Binarizer \n",
    "\n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "data = read_csv(filename, names=names) \n",
    "array = data.values\n",
    "# data\n",
    "\n",
    "# separate array into input and output components \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "binarizer = Binarizer(threshold=0.0).fit(X) \n",
    "binary_data = binarizer.transform(X) \n",
    "binary_data = pandas.DataFrame(binary_data, columns=names[:-1])\n",
    "binary_data['class'] = data['class']\n",
    "# binary_data\n",
    "\n",
    "# Group the data\n",
    "grouped_data = binary_data[['class', 'age', 'test']].groupby(['class']).sum()\n",
    "# grouped_data.values\n",
    "\n",
    "# Find p-value\n",
    "x_value, p_value, _, _ = stats.chi2_contingency(grouped_data.values)  \n",
    "print(\"The chi-square value is\", x_value, \"with a p-value of\", p_value)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Your Data With Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important charts\n",
    "\n",
    "- Line Plot\n",
    "- Bar Chart\n",
    "- Histogram Plot \n",
    "- Box and Whisker Plot \n",
    "- Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:23.878393Z",
     "start_time": "2019-10-09T04:12:22.199690Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Univariate Histograms \n",
    "from matplotlib import pyplot \n",
    "from pandas import read_csv \n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "data = read_csv(filename, names=names) \n",
    "data.hist() \n",
    "pyplot.tight_layout()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:26.160331Z",
     "start_time": "2019-10-09T04:12:23.881096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJEAAABNCAYAAACmJIZ3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAOXUlEQVR4nO2de3CU13XAf2d3tavXIvSyAAkkFLDNUwJk2UAlNyQYxwFcHE8LsdPYJqEenNppWmdSx5MmTqZpGJqxaSgTEpJJ3AcQm2RwmsFjsGuwSzECCwLibXCREFhCSOK10j5O//g+gSx2tZ/Yl2S+38w3Wu7ee8/R6ux3z3fPPQdRVWxsYsGRagVshj62EdnEjG1ENjFjG5FNzNhGZBMzthHZxIwr1Qokg4KCAi0rK0u1GkOePXv2tKpqYd/2W8KIysrKqKurS6rM85e6ePfEeT5oucRFX4Cr/iCBYOiGfv1t07mcgtvpwJPmxO10UJybQVVpLuOLvAnUPDIi8mG49lvCiJKJzx9kxZYj/HrnKQIhRQSy3C7S0xy4HA5EbhwTpgkFAiGlyx+kOxiiKxC6ZnD3lOfxoy9MpTQ/K4G/iXVsI4ojgWCIZS/vYfvRFpZUj2FJ9WhuL/KSnuaMee5QSDl94QpvNJzjpW3H+MKanbzy5EzKClJvSLZjHUf+9b9PsP1oCz98aAo/fGgKU0uGx8WAABwOoTQ/i6/UlPPb5bPwB0M8s6E+7BKZbGwjihMfdfr4yVvHmT91JEuqxyRU1rjbvLzw4CT2nW7nd/VnEirLCpaMSEReFZHPi4htdBFYu/0DgiHlm/PuTIq8hRWjmDRqGKvfOk4olNogulWjWAN8ETgmIv8kIsn5pIYI3YEQr+xt5P7JIxiTn5kUmSLCV2vKOdl6mV0n25IiMxKWjEhVt6rqI8B04BTwhoj8j4g8LiJpiVRwKPDWkY9ov+Ln4RklSZU7b9IIvB4Xv9lzOqly+2J5eRKRfOAx4CvA+8BLGEb1RkI0G0L8fn8z+VluasYVJFVuhtvJvMkj2NpwLqUOtlWfaBOwA8gEFqjqQlXdoKp/DWQnUsHBTjCk7DjWwp/ecRsuZ/Jdxs9OuI1OX4C6Dy8kXXYPVveJfq6qf+jdICIeVe1S1aoE6DVk2N/YTvsVP/fecUM0ICn8yfhC3E4Hbx7+iHvK81Oig9Wvzg/CtO2MpyJDlbePtiBC0peyHrI9LmaU5vLu8daUyIcodyIRGQEUAxkiMo3rO/TDMJa2W553j7cytTiH3Cx3ynS4uzyPl7Ydo9PnZ1h68p9zoi1n8zCc6RLgx73aLwLPJUinIUN3IMS+xg6+PLM0pXrcPTYf1WPUnWpjzp1FSZff73Kmqr9S1U8Dj6nqp3tdC1V1U7TJReR+ETkiIsdF5Fth3veIyAbz/V0iUtbrvb8324+IyDyzbbSIvCUih0TkoIg8M+DfOI4cPNNBdyDE9DG5qVSDaWOGk+aUlO0XRVvOHlXVfwPKROQbfd9X1R+HGdYz1gmsBuYCjcBuEdmsqg29ui0FLqjqOBFZDPwI+AsRmQgsBiYBo4CtInI7EAD+VlX3iogX2CMib/SZM2nsMZ+Ippem1ojS05xUlAznvRQZUTTHuidEnA14w1z9UQ0cV9UPVLUbWA882KfPg8CvzNevAJ8RETHb15tPfyeB40C1qjar6l4AVb0IHMLw2VLC+//XTkluBkXD0lOlwjWml+Zy8Ewn3YHk7xf1eydS1Z+aP793E3MXA723UhuBuyP1UdWAiHQA+Wb7//YZ+zFjMZe+acCum9AtZlSVug/buHtsah6r+1JRMpzuQIjDZzuZWjI8qbKtbjauEJFhIpImIttEpFVEHo02LExb30hhpD79jhWRbOBV4Ouq2hlB52UiUicidS0tLVFUHThnOnyc6+xiRoqXsh4qxxiGs+90e9JlW90nus/8Y83HuCvcDjwbZUwjMLrXv0uAvucWrvUREReQA7T1N9aM1b0K/Ht/zr2qrlXVKlWtKiyM/0bg3h5/KMVOdQ+jctIpyPbw/iA2op7NhweA/1RVKx7cbmC8iIwVETeGo7y5T5/NwJfN1w8Db6pRHGAzsNh8ehsLjAfeM/2ldcCh/pz6ZFB/uh2Py8GdI1Nz3rkvIkLl6JxBfSd6TUQOA1XANhEpBHz9DVDVAPA14HUMB3ijqh4UkRdEZKHZbR2QLyLHgW8A3zLHHgQ2Ag3AFuApVQ0Cs4EvAXNEpN68HhjA7xs36k+3M6U4h7QUxMsiUTl6OCdaLtNx1Z9UuWK1KoiI5AKdqhoUkUxgmKqeTah2caKqqkr7Znv4/X4aGxvx+fr9LoRFVTnT4SPb4yInY/CchPH5g7Re6qYg281wbxYlJSWkpcVPPxHZEy5WOpCD+hMw9ot6j/l1zJqliMbGRrxeL2VlZUi4FIx+uNodIPDRJcbkZTI8M3Xhjr4EQiEaznRS5PXg9F+msbGRsWPHJlyuJSMSkZeBTwH1QNBsVoawEfl8vpsyIIAr3cZHkOmOzyH8eOFyOPC4nFz1hyjNzycRT6Vh5VrsVwVM1E9YRaybMSAwjMjlcAwqf6iHTLeTi75AUmVa/RQOACMSqchQ4kp3kEy386aNsAen00llZSWTJ09mwYIFtLfH/mSV6XYSCIWSunNt1YgKgAYReV1ENvdciVRssBIMhegKBMmIw1KWkZFBfX09Bw4cIC8vj9WrV8c8Z5bHWFwudwej9IwfVo3ou8CfAf8I/HOv65YjUf7QzJkzaWpqAoynv2effZbJkyczZcoUNmzYAMDy5cvZvNn47i5atIgnnngCgHXr1vH8888D4HE5cDqEK93JW9Is+USq+raIlALjVXWr+Yg/uLzKGPjeawdpOBM2enID3cEQ/kDo2jc+EhNHDeMfFkyyNGcwGGTbtm0sXboUgE2bNlFfX8++fftobW3lrrvuora2ltraWnbs2MHChQtpamqiubkZgHfeeYfFixcDhp+X6XZxpWuQ3YlE5KsYUfafmk3FwO8SpdRgJhRSHI7YfKEerl69SmVlJfn5+bS1tTF37lzAMIolS5bgdDopKiri3nvvZffu3dTU1LBjxw4aGhqYOHEiRUVFNDc3s3PnTmbNmnVt3iy3E18gmLSkRqtPZ09hHO3YBaCqx0TktoRplWSs3jFCIeVgcycF2W5G5mTELLfHJ+ro6GD+/PmsXr2ap59+mkgPwcXFxVy4cIEtW7ZQW1tLW1sbGzduJDs7G6/3evgl0238WbuTlEZk1SfqMs8EAdeCpZ+ox30rXOkOoqpkueNbTCUnJ4dVq1axcuVK/H4/tbW1bNiwgWAwSEtLC9u3b6e6uhowfKcXX3yR2tpaampqWLlyJTU1NR+bL9PtxCGCzz+4jOhtEXkO48D+XOA3wGuJU2twcrHLjyBkeeLvDk6bNo2KigrWr1/PokWLmDp1KhUVFcyZM4cVK1YwYoSxw1JTU0MgEGDcuHFMnz6dtra2G4zI4RCyPC66AsnxiyzFzsxCDkuB+zDO+ryOkYs2JO5G4WJnhw4dYsKECQOa58jZi6Q5hfLCwZ+v2Xqpi/f3H2T87XfErYZRpNiZ1Vz8EIYjvVxVH1bVnw0VA4oXXf4gXYEgwwZRwLU/vOnGkrv10LmEy+rXiMTguyLSChwGjohIi4h8J+GaDTLazeMVqcjruhk8Lidul7Bpb1PCZUW7E30d4wzPXaqar6p5GOekZ4vI3yRcu0GCqnLhcjfZHhdu1+CLl0Ui0+2iobmTA00dCZUT7RP5S2CJmXEBgKp+ADxqvjeksboid1z10x0MkZ89eI59RENVyXQ7yXI7WfP2iYTKimZEaap6Q5K3qrZw/chsROKdvGhlTqukp6dz/vz5qIYUDClnO32kpzmHzFKmqpw/f57MjAwem13GH/7YTN2pxOWkRdvw6L7J9xKVvIiFOS1RUlJCY2Njv2duVJW2y358/iAFXg+H24bOUpaenk5JSQlPjoTN+87wzPp61i+7h9F58S+hEM2IKkQkXFBJgGgZe9eSFwFEpCd5sfcf/EGM4C4YYZWf9E1eBE6aZ7CrzX7R5oxIMKT4gyGCISWokFtUbL5WQiHMn0r7FT/7m9p5eeeHHD57ke/Mn8hnpyT+hGAiSEuDNY/M4JGf7+KBVTt4fPZYZn8qn+LcDDLSnHjSnLgihHEcIpZ8wGjJi7HsqiUqeTHanBH55bsn+cF/HbLanfLCLNZ+aQb3TRraR6kmF+fw2+Wz+P7vG/iXN4+xatsxS+PuKc9j/bKZUfslshh6IpIXw30twjo1IrIMWAYwZoxREriqLI9v3n8HThGcDsHR89MhZpvx7fOmuxhf5KW8ICvmg2eDhfLCbH75eDUtF7s41NxJc8dVfH7jbFTvEJv2+jiLh1uLDybSiAaSvNhoNXnRwpyAkbwIrAVjxxqMlJrK0clNMR5sFHo9FHrjm8xpOWVowBMbRnEU+AzQhJHM+EUzp6ynz1PAFFV90nSsH1LVPxeRScB/YPhBo4BtGAmMEm3OCLq0AGH/c5MYKQBSVaIsFbJLw/0vQ6hqwi6MjNmjwAng22bbC8BC83U6RjD3OPAeUN5r7LfNcUeAz/U3Z6ouoO5WlN33Stid6FZAROo0RYVPUym7L0Nn48Nm0GIbUWysvUVlfwx7ObOJGftOZBMzthHdBPEKAvczf9gquebZrqZwZXUiBayTQqofD4fahZFvdwIoB9zAPow6BfGUMRKYbr72YmxpTMSIM/5dmP4TTT08wFhTP2eyPhP7TjRwrFTFjQkdeJXcsNV246lTf9hGNHDCBZYTVgY5TJXcr4nIfhH5hVl4LOk69cU2ooFjJbAcH0E3Vsldg1EnqhJo5no9hKTpFA7biAaOlcByzISrkquq51Q1qEb2zc+4vmQlRadI2EY0cKxUxY2JSFVyRWRkr26LMOpGQYRqu/HUqT8SeRTkE4kah+d6quI6gV9olFMEN0FPldw/iki92fYcsEREKjGWqlPAX5k6HRSRnmq7Aa5X200K9o61TczYy5lNzNhGZBMzthHZxIxtRDYxYxuRTczYRmQTM7YR2cSMbUQ2MfP/wZdjfmzQz1sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Univariate Density Plots \n",
    "from matplotlib import pyplot \n",
    "from pandas import read_csv \n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "data = read_csv(filename, names=names) \n",
    "data.plot(kind='density' , subplots=True, layout=(4,4), sharex=False) \n",
    "pyplot.tight_layout()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:27.788115Z",
     "start_time": "2019-10-09T04:12:26.163023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKEAAABlCAYAAAAlKIMUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAFFUlEQVR4nO3dX4hUZRzG8e+TriAUpriFmDpdeKEUWlgYaTdGmEFGUNaFSQjeCCUktXQTQYEhRAQVCAkGUQQlRXaRWJSR/VnNP9USLZVlma1Fm9FCJr8uzhG3nNyRztnfuPN8YNnZd84Or/L1nJmdd30VEZhlOi97AmaO0NI5QkvnCC2dI7R0jtDSjc+eAMDUqVOj0WhkT8NqtHv37qMR0d3svraIsNFo0Nvbmz0Nq5Gkg/91ny/Hlq4tzoRjnaSWjuvUd698JhwFEXHax6wHXj9trFM5QkvnCC2dI7R0jtDSOUJL5wgtnSO0dI7Q0jlCS+cILZ0jtHSO0NI5QkvnCC2d1xNWbN7DbzI4dLylYxs92854/6SJXex76IYqptXWHGHFBoeO882Gmyp5rJEiHStGvBxLmiHpbUl9kj6TdG85PkXSdklflp8nl+OS9KSkfkn7JV1Z9x/Czm2tPCf8C7gvIuYAC4G1kuYCPcCOiJgN7Ci/BrgRmF1+rAGeqXzWNqaMGGFEHI6IPeXtY0AfMB1YDmwpD9sC3FLeXg48F4UPgAslTat85jZmnNWrY0kN4ArgQ+DiiDgMRajAReVh04Hvhn3boXLs34+1RlKvpN6BgYGzn7mNGS1HKOl84GVgXUT8dqZDm4yd9ls8EbEpIhZExILu7qa/E20doqUIJXVRBPh8RLxSDh85eZktP/9Ujh8CZgz79kuAH6qZro1Frbw6FvAs0BcRjw+76zVgVXl7FfDqsPG7ylfJC4HBk5dts2Za+TnhtcBK4ICkveXYg8AG4CVJq4FvgdvK+94AlgH9wB/A3ZXO2MacESOMiPdo/jwPYEmT4wNY+z/nZR3E7x1bOkdo6RyhpXOEls4RWjov5arYBXN6uHxLz8gHtvRYANUsC2tnjrBix/o2eD3hWfLl2NI5QkvnCC2dI7R0jtDSOUJL5wgtnSO0dI7Q0jlCS+cILZ0jtHSO0NI5QkvnpVw1qGoJ1qSJXZU8TrtzhBVrdS1ho2dbZesOz3W+HFs6R2jpHKGlc4SWzhFaOkdo6RyhpXOEls4RWjpHaOlqiVDSUklflLs6VfMfs9iYVXmEksYBT1Hs7DQXuLPcAcqsqTrOhFcD/RHxVUT8CbxIscuTWVN1RNjSjk5mJ9WxlKulHZ0kraHYgJGZM2fWMI32UWwF02T8sX9+XWx80HnqOBO2tKNTJ20rFhEtfXSqOiL8GJgt6VJJE4A7KHZ5MmtKdfwLlLQMeAIYB2yOiEdHOH4AOFj5RNrbVOBo9iRG0ayIaHrJqyVCG5mk3ohYkD2PduB3TCydI7R0jjDPpuwJtAs/J7R0PhNaOv/ye8UknQAOUPzdfg2sjIhfc2fV3nwmrN5QRMyPiMuAX/AG5CNyhPXaRbl4Q4WNkj6VdEDSinL8aUk3l7e3Stpc3l4t6ZG0mY8iR1iTcl3lEk69ZXkrMB+YB1wPbJQ0DXgXWFweM51iDSbAImDnqE04kSOs3kRJe4GfgSnA9nJ8EfBCRJyIiCPAO8BVFKEtLhf+fg4cKeO8Bnh/1GefwBFWbygi5gOzgAmcek7YdD1XRHwPTAaWUpwVdwK3A79HxLH6p5vPEdYkIgaBe4D1krooAlshaZykbuA64KPy8F3AOk5FuJ4OuRSDI6xVRHwC7KNYzrYV2F9+/RZwf0T8WB66ExgfEf3AHorLeMdE6HdMLJ3PhJbOEVo6R2jpHKGlc4SWzhFaOkdo6Ryhpfsbmr1zp/hhd7MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Box and Whisker Plots \n",
    "from matplotlib import pyplot \n",
    "from pandas import read_csv \n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "data = read_csv(filename, names=names) \n",
    "data.plot(kind='box' , subplots=True, layout=(3,3), sharex=False, sharey=False) \n",
    "pyplot.tight_layout()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:28.083983Z",
     "start_time": "2019-10-09T04:12:27.790696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation Matrix Plot \n",
    "from matplotlib import pyplot \n",
    "from pandas import read_csv \n",
    "import numpy \n",
    "filename = 'breast_cancer_data.csv'\n",
    "names = ['Row', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', 'Single Epithelial  Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "data = read_csv(filename, names=names) \n",
    "correlations = data.corr() \n",
    "\n",
    "# plot correlation matrix \n",
    "fig = pyplot.figure() \n",
    "ax = fig.add_subplot(111) \n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1) \n",
    "fig.colorbar(cax) \n",
    "ticks = numpy.arange(0,11,1) \n",
    "ax.set_xticks(ticks) \n",
    "ax.set_yticks(ticks) \n",
    "ax.set_xticklabels(names) \n",
    "ax.set_yticklabels(names) \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:36.488051Z",
     "start_time": "2019-10-09T04:12:28.086460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEMCAYAAADHxQ0LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAQK0lEQVR4nO3df4xlZX3H8feHHbAWXQEZTdXSjbY2Ii4UdwWFhQJrS9OKYkTbVJtUm7WJjVojjW3qHzVNCzFmQ2KN3bS2qRqaVEWoWtRVF5bwc8AKjVajVf9QwEXcXTUusMu3f9wzMszO7s7O3HMv9z7vVzLZc8798XyfXO7nHJ7nnHNTVUiSpt8x4y5AkjQaBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiNmxl3AoZx88sm1bt26cZchSRPlzjvvfKCqZpd67Akb+OvWrWNubm7cZUjSREny3UM95pCOJDXCwJekRhj4ktQIA1+SGmHgS1Ijegv8JKcluTnJziT/koGt3fpVfbUrSVpan0f4X6+ql1XVpm79JcDx3fpxSTb22LYkaZHeAr+qHlmw+hCwGdjerW8Hzu6rbUnSwXq98CrJJcDfAd8A7gX2dg/tAV64xPO3AFsATjnllMO+97p3fXqYpUrSRPjOFb+74tf2OmlbVddV1WnA94D9wNruobXA7iWev62qNlTVhtnZJa8MliStUJ+Ttk9asLoXKOCibn0zcGtfbUuSDtbnEf7FSW5IcgPwTOAKYF+SncCjVXV7j21LkhbpbQy/qq4Frl20+W19tSdJOjwvvJKkRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGtFb4Cc5K8nNSXYm2dpt25NkR/d3Ul9tS5IONtPje38XuLCq9iX5aJIXAfdU1W/22KYk6RB6O8Kvqvuqal+3uh84ALygO+K/Ikn6aluSdLDex/CTrAdOrqqvAr8GnAecCLxiieduSTKXZG7Xrl19lyZJTek18Ltx+vcDbwKoqgerqoBPAqctfn5VbauqDVW1YXZ2ts/SJKk5fU7azgAfAS6vqvuSHJ9kTffwOcC3+mpbknSwPo/wLwM2Alcm2QGsB+5IshP4ZeBjPbYtSVqkt7N0qupq4OpFm8/sqz1J0uF54ZUkNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RG9Bb4Sc5KcnOSnUm2dtsuT3JTko8mObavtiVJB+vzCP+7wIVVtQl4RpJNwAVVdS5wN/CqHtuWJC3SW+BX1X1Vta9b3Q+sB3Z069uBs/tqW5J0sN7H8JOsB04GdgN7u817gBOXeO6WJHNJ5nbt2tV3aZLUlF4DP8lJwPuBNzEI/LXdQ2u79cepqm1VtaGqNszOzvZZmiQ1p89J2xngI8DlVXUfcAdwfvfwZuDWvtqWJB2szyP8y4CNwJVJdgDPA25MchNwBvDJHtuWJC0y09cbV9XVwNWLNt8CXNlXm5KkQ/PCK0lqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSI5YV+Enek+TlSY7vuyBJUj+We4T/HeAPgLkktyd5X5JX9leWJGnYlhX4VfWhqnojcAGDHya/rPtXkjQhlvWbtkn+CTgVuB/YCbwGuKvHuiRJQ7bcIZ2nA2uA3cCDwANVtb+3qiRJQ7esI/yquhQgyQuA3wa+lGRNVT2nz+IkScOz3CGd3wM2AecBJwJfZDC0I0maEMsKfOB3gBuBq6rq+z3WI0nqyXKHdN6S5JnAxiRnArdX1Q/6LU2SNEzLvfDqMuB2Bqdjvha4Lclr+ixMkjRcyx3S+Wtg4/xRfZJZYDvwsb4KkyQN13JPyzxm0RDOD4/02iTPSnJXkn1JZpKsS3J/kh1JPrfiiiVJK7LcI/zrk3wWuLpbfx3wX0d4zYPARcA1C7Z9vqpef3QlSpKGYbmTtpcneTVwLhBgW1Vdc4TX7AP2JVm4+YIkO4FPVNXWFdYsSVqB5R7hU1WfAD4BkGRNkj+sqo8eRVv3As8HHgKuTfKFqrp74ROSbAG2AJxyyilH8daSpCM50jj82iR/meT9SX4rA38G/B+Ds3WWraoeqqqfdrdk+BRw2hLP2VZVG6pqw+zs7NG8vSTpCI40afth4NeBe4A/AT7H4NTMV1bVUd0eOclTF6yeA3zraF4vSVqdIw3pPLeqXgQ/v2PmA8ApVfXjI71xkmMZTOyeDnwWuDHJJQyGdG6qqttWVbkk6agcKfAfmV+oqgNJvr2csO+e/wiwedHmvznK+iRJQ3KkwD89yd5uOcCTu/UAVVVre61OkjQ0hw38qlozqkIkSf1a7pW2kqQJZ+BLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1IjeAj/Js5LclWRfkplu29YkO5Nc1Ve7kqSl9XmE/yBwEXArQJIzgeOrahNwXJKNPbYtSVqkt8Cvqn1V9aMFm14KbO+WtwNn99W2JOlgoxzDPwHY2y3vAU4cYduS1LxRBv5uYG23vLZbf5wkW5LMJZnbtWvXCEuTpOk3ysC/hcGYPsBmurH9hapqW1VtqKoNs7OzIyxNkqZfn2fpHJtkO3A68FngWGBfkp3Ao1V1e19tS5IONtPXG1fVIwyO5Be6ra/2JEmH54VXktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjRhr4SdYluT/JjiSfG2XbktS6mTG0+fmqev0Y2pWkpo1jSOeCJDuT/PkY2pakZo068O8Fng9cAGxOsn7hg0m2JJlLMrdr164RlyZJ022kgV9VD1XVT6tqP/Ap4LRFj2+rqg1VtWF2dnaUpUnS1Bv1pO1TF6yeA3xrlO1LUstGPaSzKcmdSW4Gvl9Vt424fUlq1kjP0qmqzwCfGWWbkqQBL7ySpEYY+JLUCANfkhph4EtSIwx8SWqEgS9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqhIEvSY0w8CWpEQa+JDXCwJekRhj4ktQIA1+SGmHgS1IjDHxJaoSBL0mNMPAlqREGviQ1wsCXpEYY+JLUiJEHfpKtSXYmuWrUbUtSy0Ya+EnOBI6vqk3AcUk2jrJ9SWrZqI/wXwps75a3A2ePuH1JataoA/8EYG+3vAc4ccTtS1KzZkbc3m5gbbe8tlv/uSRbgC3d6k+SfP0w73Uy8MDQKxy/aeyXfZoc09ivqepTrgQO36dfOeRrq6qHkg7R2GAM/81V9eYkHwD+tapuX+F7zVXVhuFWOH7T2C/7NDmmsV/26TEjHdKpqruAfUl2Ao+uNOwlSUdv1EM6VNXbRt2mJGmyL7zaNu4CejKN/bJPk2Ma+2WfOiMdw5ckjc8kH+FLko6CgS9JjRj5pO1KJXkxgytzT2Rw/v6tVTU33qokaXJMxBh+kq3AkxjcjmEPg4u2NgMHquqt46xtNZKsAV7Foh0Z8Mmq2j/O2lZjGnfO0/hZTWmfngL8KYM+ncBjffrHqvrxOGtbjWF9pyYl8G+sqvOWu31SJPkwcDfwBR6/Izu9ql4/ztpWaop3ztP4WU1jn64DPszBffqjqnrFOGtbqWF+pyZlSGcuyQcZdHgvgw5fBNw11qpWb11VvWHRti93F6ZNqhcvsRO+JsmNY6lmeKbxs5rGPj0d+HhVPdqt/yjJx4G3j7Gm1Rrad2oiAr+q3pHkNxjcbfP5DP6XZltVfXm8la3adUk+BezgsR3Z+cB/jrOoVZrWnfO1iz6rpwHnMdmf1TT26R+AHUnu5rE+vRD4wFirWp2hfacmYkhnmiU5GXgJ8GLgm8A3q+qO8Va1Ogt2zk/jsfHGSd85L/ys5seG76iqXeOtanUW9Gn+s5qbgj7NMDgwnP+cvjGpcxLzhvWd8rTMMUpyfVU9wOA/zrMYfJhvTXLFeCtbtWO6vxlgTfc38arqgar6DINx77XAuvFWtDrdpO35wIUMxoQvAs7vAnMiJTmhqvZX1VeBk4BLgEuTZMylrdZQvlMe4Y9Rki9W1YVJbgAumB93THJTVZ075vJWpJtgOo6DJ80mfdL2+qq6OMnbGQTjp4FzgO9V1bvGW93KdJO293DwZOAkT9rOf6f+nsER/rUMPqfnVNUfj7e6lRnmd2pi9+RT4tQk/wY8j8Es/M+67b8wvpJWbVonbY/r/r2Ux3bOH0xy0xhrWq1pnLSd97KqOr9bvr47qJpUbU3aTrGzun/fDeyHn59H/O6xVbR60zppO40750OdNHDdOItapTO7IDy1G97ZneQY4CnjLmwVnLTVE9eCCab5SbNbgJlJnoxOsvBXhO6tqoe7nfM7quo946prtZKcC7yIwee0B7gDeG5V3TbWwlYhyWkMhju+1q3/IrC+qm4db2Url+QlDEJ+hsHBYVXVUc/1Gfgaqu5o6qDNwPVV9fJR1zMs09ivJO8DngEcYHD++huratf8OPh4q1uZKe3TP3eLDwOzwPcZHOk/o6q2HPKFS3BIR8P2EwaXsi8UYP0Yahmm+X4FmD9KmvR+bZgf506yHviPJJePuabVmsY+/eqCPt1TVa/plr90tG9k4GvYvgZcWlV7Fm5M8vkx1TMs09ivmSTHVdXDVXV3kkuBjzC4UGlSTWWfFiz/1YLloz7V1CEdDVWSXwJ+WFUPL9o+M8kXv0xjv7px4e9U1Q8WbFsDXFZV/z6+ylZuSvv0QuB/q+rAgm3HARdX1VFNsBv4ktQIr7SVpEYY+JLUCCdtpQWSHGBwu4EZ4NvAG6pq93irkobDI3zp8X5WVWdU1WnAg8Bbxl2QNCwGvnRotwDPBsjAe5P8T5J7kryu2/6BJJd0y9ck+VC3/KYkfzu2yqUlGPjSErpT+S7isfvKvBo4AzidwZ0K39udqnkjsKl7zrOBU7vlc4FpuAmZpoiBLz3ek5P8N/BDBvdTn7+w6lzg6qo6UFX3AzcAGxmE+qYkpwJfBe7vdgQvBW4eefXSYRj40uP9rKrOAH6FwS2R58fwl7yqsaq+B5wIXMzgaH8n8FrgJ1X14/7LlZbPwJeW0N1C4a3AO5McyyDMX5dkTZJZBr/9env39FsY/Ej2fOC/E4dz9ARk4EuH0P1m6FeA3weuYfDThl8Bvgj8RVXd1z11J4PbP3+TwT3KT8LA1xOQt1aQpEZ4hC9JjTDwJakRBr4kNcLAl6RGGPiS1AgDX5IaYeBLUiMMfElqxP8DKme76MLpFjcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scatterplot Matrix \n",
    "from matplotlib import pyplot \n",
    "from pandas import read_csv \n",
    "from pandas.plotting import scatter_matrix \n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "data = read_csv(filename, names=names) \n",
    "scatter_matrix(data) \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Your Data For Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescaling\n",
    "\n",
    "- When your data is comprised of attributes with varying scales, many machine learning algorithms can benefit from rescaling the attributes to all have the same scale. \n",
    "- Often this is referred to as normalization and attributes are often rescaled into the range between 0 and 1. \n",
    "- This is useful for optimization algorithms used in the core of machine learning algorithms like gradient descent. \n",
    "- It is also useful for algorithms that weight inputs like regression and neural networks and algorithms that use distance measures like k-Nearest Neighbors.\n",
    "\n",
    "![](images/scaled_value.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:36.509884Z",
     "start_time": "2019-10-09T04:12:36.490693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.353 0.744 0.59  0.354 0.    0.501 0.234 0.483]\n",
      " [0.059 0.427 0.541 0.293 0.    0.396 0.117 0.167]\n",
      " [0.471 0.92  0.525 0.    0.    0.347 0.254 0.183]\n",
      " [0.059 0.447 0.541 0.232 0.111 0.419 0.038 0.   ]\n",
      " [0.    0.688 0.328 0.354 0.199 0.642 0.944 0.2  ]]\n"
     ]
    }
   ],
   "source": [
    "# Rescale data (between 0 and 1) \n",
    "from pandas import read_csv \n",
    "from numpy import set_printoptions \n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "\n",
    "# separate array into input and output components \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "scaler = MinMaxScaler(feature_range=(0, 1)) \n",
    "rescaledX = scaler.fit_transform(X) \n",
    "\n",
    "# summarize transformed data \n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "\n",
    "- Standardization is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1. \n",
    "- It is most suitable for techniques that assume a Gaussian distribution in the input variables and work better with rescaled data, such as linear regression, logistic regression and linear discriminate analysis.\n",
    "\n",
    "![](images/standard_mean.png)\n",
    "\n",
    "![](images/standard_dev.png)\n",
    "\n",
    "![](images/standardized_value.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:36.532974Z",
     "start_time": "2019-10-09T04:12:36.512080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64   0.848  0.15   0.907 -0.693  0.204  0.468  1.426]\n",
      " [-0.845 -1.123 -0.161  0.531 -0.693 -0.684 -0.365 -0.191]\n",
      " [ 1.234  1.944 -0.264 -1.288 -0.693 -1.103  0.604 -0.106]\n",
      " [-0.845 -0.998 -0.161  0.155  0.123 -0.494 -0.921 -1.042]\n",
      " [-1.142  0.504 -1.505  0.907  0.766  1.41   5.485 -0.02 ]]\n"
     ]
    }
   ],
   "source": [
    "# Standardize data (0 mean, 1 stdev) \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from pandas import read_csv \n",
    "from numpy import set_printoptions \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "\n",
    "# separate array into input and output components \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "scaler = StandardScaler().fit(X) \n",
    "rescaledX = scaler.transform(X) \n",
    "\n",
    "# summarize transformed data \n",
    "set_printoptions(precision=3) \n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "- Normalizing in scikit-learn refers to rescaling each observation (row) to have a length of 1 (called a unit norm or a vector with the length of 1 in linear algebra). \n",
    "- This pre-processing method can be useful for sparse datasets (lots of zeros) with attributes of varying scales when using algorithms that weight input values such as neural networks and algorithms that use distance measures such as k-Nearest Neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:36.563359Z",
     "start_time": "2019-10-09T04:12:36.541630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.034 0.828 0.403 0.196 0.    0.188 0.004 0.28 ]\n",
      " [0.008 0.716 0.556 0.244 0.    0.224 0.003 0.261]\n",
      " [0.04  0.924 0.323 0.    0.    0.118 0.003 0.162]\n",
      " [0.007 0.588 0.436 0.152 0.622 0.186 0.001 0.139]\n",
      " [0.    0.596 0.174 0.152 0.731 0.188 0.01  0.144]]\n"
     ]
    }
   ],
   "source": [
    "# Normalize data (length of 1) \n",
    "from sklearn.preprocessing import Normalizer \n",
    "from pandas import read_csv \n",
    "from numpy import set_printoptions \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "\n",
    "# separate array into input and output components \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "scaler = Normalizer().fit(X) \n",
    "normalizedX = scaler.transform(X) \n",
    "\n",
    "# summarize transformed data \n",
    "set_printoptions(precision=3) \n",
    "print(normalizedX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarization\n",
    "\n",
    "- You can transform your data using a binary threshold. \n",
    "- All values above the threshold are marked 1 and all equal to or below are marked as 0. \n",
    "- This is called binarizing your data or thresholding your data. \n",
    "- It can be useful when you have probabilities that you want to make into crisp values. \n",
    "- It is also useful when feature engineering and you want to add new features that indicate something meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:36.593840Z",
     "start_time": "2019-10-09T04:12:36.569320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 0. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# binarization \n",
    "from sklearn.preprocessing import Binarizer \n",
    "from pandas import read_csv\n",
    "from numpy import set_printoptions \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "\n",
    "# separate array into input and output components \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "binarizer = Binarizer(threshold=0.0).fit(X) \n",
    "binaryX = binarizer.transform(X) \n",
    "\n",
    "# summarize transformed data \n",
    "set_printoptions(precision=3) \n",
    "print(binaryX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection For Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate selection\n",
    "\n",
    "- The Pearson’s Chi-Squared test, or just Chi-Squared test for short, is named for Karl Pearson, although there are variations on the test. \n",
    "- The Chi-Squared test is a statistical hypothesis test that assumes (the null hypothesis) that the observed frequencies for a categorical variable match the expected frequencies for the categorical variable. \n",
    "- The test calculates a statistic that has a Chi-Squared distribution, named for the Greek lowercase letter chi (χ) pronounced “ki” as in “kite”.\n",
    "- Statistical tests can be used to select those features that have the strongest relationship with the output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:36.797164Z",
     "start_time": "2019-10-09T04:12:36.597456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 111.52  1411.887   17.605   53.108 2175.565  127.669    5.393  181.304]\n",
      "[[148.    0.   33.6  50. ]\n",
      " [ 85.    0.   26.6  31. ]\n",
      " [183.    0.   23.3  32. ]\n",
      " [ 89.   94.   28.1  21. ]\n",
      " [137.  168.   43.1  33. ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2175.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plas</th>\n",
       "      <td>1411.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>181.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mass</th>\n",
       "      <td>127.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preg</th>\n",
       "      <td>111.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skin</th>\n",
       "      <td>53.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pres</th>\n",
       "      <td>17.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pedi</th>\n",
       "      <td>5.393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "test  2175.565\n",
       "plas  1411.887\n",
       "age    181.304\n",
       "mass   127.669\n",
       "preg   111.520\n",
       "skin    53.108\n",
       "pres    17.605\n",
       "pedi     5.393"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Extraction with Univariate Statistical Tests (Chi-squared for classification) \n",
    "from pandas import read_csv \n",
    "from numpy import set_printoptions \n",
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import chi2 \n",
    "\n",
    "# load data \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "\n",
    "# feature extraction \n",
    "test = SelectKBest(score_func=chi2, k=4) \n",
    "fit = test.fit(X, Y) \n",
    "\n",
    "# summarize scores\n",
    "set_printoptions(precision=3) \n",
    "print(fit.scores_) \n",
    "features = fit.transform(X) \n",
    "\n",
    "# summarize selected features \n",
    "print(features[0:5,:])\n",
    "pandas.DataFrame(fit.scores_.reshape(1, 8).tolist(), columns=names[:-1]).T.sort_values(0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive feature elimination\n",
    "\n",
    "- The Recursive Feature Elimination (or RFE) works by recursively removing attributes and building a model on those attributes that remain. \n",
    "- It uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:36.854081Z",
     "start_time": "2019-10-09T04:12:36.799880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 3\n",
      "Selected Features: [ True False False False False  True  True False]\n",
      "Feature Ranking: [1 2 3 5 6 1 1 4]\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction with RFE \n",
    "from pandas import read_csv \n",
    "from sklearn.feature_selection import RFE \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "# load data \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class' ] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "\n",
    "# feature extraction \n",
    "model = LogisticRegression() \n",
    "rfe = RFE(model, 3) \n",
    "fit = rfe.fit(X, Y) \n",
    "print(\"Num Features: %d\" % fit.n_features_) \n",
    "print(\"Selected Features: %s\" % fit.support_) \n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)\n",
    "# pd.DataFrame(fit.ranking_.reshape(1, 8).tolist(), columns=names[:-1]).T.sort_values(0, ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal component analysis\n",
    "\n",
    "- Principal Component Analysis (or PCA) uses linear algebra to transform the dataset into a compressed form. \n",
    "- Generally this is called a data reduction technique. \n",
    "- A property of PCA is that you can choose the number of dimensions or principal components in the transformed result.\n",
    "\n",
    "As intuition:\n",
    "- It can be thought of as a projection method where data with m-columns (features) is projected into a subspace with m or fewer columns, whilst retaining the essence of the original data. \n",
    "- The PCA method can be described and implemented using the tools of linear algebra.\n",
    "\n",
    "![](images/pca01.png)\n",
    "![](images/pca02.png)\n",
    "![](images/pca03.png)\n",
    "![](images/pca04.png)\n",
    "![](images/pca05.png)\n",
    "![](images/pca06.png)\n",
    "![](images/pca07.png)\n",
    "\n",
    "- Where $A$ is the original data that we wish to project, $B^T$ is the transpose of the chosen principal components and $P$ is the projection of $A$. \n",
    "- This is called the covariance method for calculating the PCA, although there are alternative ways to calculate it.\n",
    "\n",
    "Also:\n",
    "\n",
    "- The eigenvectors represent the directions or components for the reduced subspace of $B$, whereas the eigenvalues represent the magnitudes for the directions. \n",
    "- The eigenvectors can be sorted by the eigenvalues in descending order to provide a ranking of the components or axes of the new subspace for $A$. \n",
    "- If all eigenvalues have a similar value, then we know that the existing representation may already be reasonably compressed or dense and that the projection may offer little. \n",
    "- If there are eigenvalues close to zero, they represent components or axes of $B$ that may be discarded. \n",
    "- A total of $m$ or less components must be selected to comprise the chosen subspace. Ideally, we would select k eigenvectors, called principal components, that have the $k$ largest eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:36.883373Z",
     "start_time": "2019-10-09T04:12:36.856382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: [0.889 0.062 0.026]\n",
      "[[-2.022e-03  9.781e-02  1.609e-02  6.076e-02  9.931e-01  1.401e-02\n",
      "   5.372e-04 -3.565e-03]\n",
      " [-2.265e-02 -9.722e-01 -1.419e-01  5.786e-02  9.463e-02 -4.697e-02\n",
      "  -8.168e-04 -1.402e-01]\n",
      " [-2.246e-02  1.434e-01 -9.225e-01 -3.070e-01  2.098e-02 -1.324e-01\n",
      "  -6.400e-04 -1.255e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction with PCA \n",
    "from pandas import read_csv \n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "# load data \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class']\n",
    "\n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "\n",
    "# feature extraction \n",
    "pca = PCA(n_components=3) \n",
    "fit = pca.fit(X) \n",
    "\n",
    "# summarize components \n",
    "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_) \n",
    "print(fit.components_)\n",
    "# pd.DataFrame(fit.components_[0].reshape(1, 8).tolist(), columns=names[:-1]).T.sort_values(0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance \n",
    "\n",
    "- Bagged decision trees like Random Forest and Extra Trees can be used to estimate the importance of features.\n",
    "\n",
    "This is based on information theory:\n",
    "- Information theory is concerned with data compression and transmission and builds upon probability and supports machine learning.\n",
    "- Information provides a way to quantify the amount of surprise for an event measured in bits.\n",
    "\n",
    "![](images/entropy.png)\n",
    "\n",
    "- Entropy provides a measure of the average amount of information needed to represent an event drawn from a probability distribution for a random variable.\n",
    "\n",
    "\n",
    "### Information gain\n",
    "- Information gain is the reduction in entropy or surprise by transforming a dataset and is often used in training decision trees.\n",
    "- Information gain is calculated by comparing the entropy of the dataset before and after a transformation.\n",
    "\n",
    "![](images/information_gain.png)\n",
    "\n",
    "- Where $IG(S, a)$ is the information for the dataset $S$ for the variable $a$ for a random variable, conditional entropy for the dataset given the variable $a$. \n",
    "- This calculation describes the gain in $H(S)$ is the entropy for the dataset before any change (described above) and $H(S|a)$ is the the dataset $S$ for the variable $a$. \n",
    "- It is the number of bits saved when transforming the dataset. \n",
    "- The conditional entropy can be calculated by splitting the dataset into groups for each observed value of $a$ and calculating the sum of the ratio of examples in each group out of the entire dataset multiplied by the entropy of each group.\n",
    "\n",
    "![](images/entropy_grouped_samples.png)\n",
    "\n",
    "- Where $\\frac{Sa(v)}{S}$ is the ratio of the number of examples in the dataset with variable $a$ has the value $v$, and $H(Sa(v))$ is the entropy of group of samples where variable $a$ has the value $v$.\n",
    "\n",
    "![](images/information_gain_dataset.png)\n",
    "\n",
    "### Mutual information\n",
    "- Mutual information calculates the statistical dependence between two variables and is the name given to information gain when applied to variable selection.\n",
    "\n",
    "![](images/mutual_information.png)\n",
    "\n",
    "- Where $I(X; Y)$ is the mutual information for $X$ and $Y, H(X)$ is the entropy for $X$ and information is a measure of dependence or mutual dependence between two random variables.\n",
    "- $H(X|Y)$ is the conditional entropy for $X$ given $Y$. The result has the units of bits. \n",
    "- As such, the measure is symmetrical, meaning that $I(X; Y) = I(Y;X)$.\n",
    "\n",
    "Also:\n",
    "- Mutual information is always larger than or equal to zero, where the larger the value, the greater the relationship between the two variables. \n",
    "- If the calculated result is zero, then the variables are independent. \n",
    "- Mutual information is often used as a general form of a correlation coefficient, e.g. a measure of the dependence between random variables. \n",
    "- It is also used as an aspect in some machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:37.014998Z",
     "start_time": "2019-10-09T04:12:36.886746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.098 0.238 0.091 0.07  0.08  0.138 0.132 0.154]\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance with Extra Trees Classifier \n",
    "from pandas import read_csv \n",
    "from sklearn.ensemble import ExtraTreesClassifier \n",
    "\n",
    "# load data \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "\n",
    "# feature extraction \n",
    "model = ExtraTreesClassifier() \n",
    "model.fit(X, Y) \n",
    "print(model.feature_importances_)\n",
    "# pd.DataFrame(model.feature_importances_.reshape(1, 8).tolist(), columns=names[:-1]).T.sort_values(0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Performance of Machine Learning Algorithms with Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train set and test set\n",
    "\n",
    "- The simplest method that we can use to evaluate the performance of a machine learning algorithm is to use different training and testing datasets. \n",
    "- We can take our original dataset and split it into two parts. Train the algorithm on the first part, make predictions on the second part and evaluate the predictions against the expected results. \n",
    "- The size of the split can depend on the size and specifics of your dataset.\n",
    "- This algorithm evaluation technique is very fast. \n",
    "- It is ideal for large datasets (millions of records) where there is strong evidence that both splits of the data are representative of the underlying problem. \n",
    "- Because of the speed, it is useful to use this approach when the algorithm you are investigating is slow to train. \n",
    "- A downside of this technique is that it can have a high variance. \n",
    "- This means that differences in the training and test dataset can result in meaningful differences in the estimate of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:37.043022Z",
     "start_time": "2019-10-09T04:12:37.017618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.591%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using a train and a test set \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "test_size = 0.33 \n",
    "seed = 7 \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression() \n",
    "model.fit(X_train, Y_train) \n",
    "result = model.score(X_test, Y_test) \n",
    "print(\"Accuracy: %.3f%%\" % (result*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "\n",
    "- Cross-validation is an approach that you can use to estimate the performance of a machine learning algorithm with less variance than a single train-test set split. \n",
    "- It works by splitting the dataset into $k$-parts. \n",
    "- Each split of the data is called a fold. \n",
    "- The algorithm is trained on $k − 1$ folds with one held back and tested on the held back fold. \n",
    "- This is repeated so that each fold of the dataset is given a chance to be the held back test set. \n",
    "- After running cross-validation you end up with $k$ different performance scores that you can summarize using a mean and a standard deviation. \n",
    "- The result is a more reliable estimate of the performance of the algorithm on new data. \n",
    "- It is more accurate because the algorithm is trained and evaluated multiple times on different data. \n",
    "- The choice of $k$ must allow the size of each test partition to be large enough to be a reasonable sample of the problem, while allowing enough repetitions of the train-test evaluation of the algorithm to provide a fair estimate of the algorithms performance on unseen data.\n",
    "\n",
    "![](images/fold_size.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:37.168104Z",
     "start_time": "2019-10-09T04:12:37.045853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.951% (4.841%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Cross Validation \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = LogisticRegression() \n",
    "results = cross_val_score(model, X, Y, cv=kfold) \n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave one out cross-validation\n",
    "\n",
    "- You can configure cross-validation so that the size of the fold is 1 (k is set to the number of observations in your dataset). \n",
    "- This variation of cross-validation is called leave-one-out cross- validation. \n",
    "- The result is a large number of performance measures that can be summarized in an effort to give a more reasonable estimate of the accuracy of your model on unseen data. \n",
    "- A downside is that it can be a computationally more expensive procedure than $k$-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:47.427213Z",
     "start_time": "2019-10-09T04:12:37.171310Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.823% (42.196%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Leave One Out Cross Validation \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import LeaveOneOut \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "loocv = LeaveOneOut() \n",
    "model = LogisticRegression() \n",
    "results = cross_val_score(model, X, Y, cv=loocv) \n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated random train-test split\n",
    "\n",
    "- Another variation on $k$-fold cross-validation is to create a random split of the data like the train/test split described above, but repeat the process of splitting and evaluation of the algorithm multiple times, like cross-validation. \n",
    "- This has the speed of using a train/test split and the reduction in variance in the estimated performance of $k$-fold cross-validation. \n",
    "- You can also repeat the process many more times as needed to improve the accuracy. \n",
    "- A down side is that repetitions may include much of the same data in the train or the test split from run to run, introducing redundancy into the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:47.534951Z",
     "start_time": "2019-10-09T04:12:47.430472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.496% (1.698%)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using Shuffle Split Cross Validation \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import ShuffleSplit \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "n_splits = 10 \n",
    "test_size = 0.33 \n",
    "seed = 7 \n",
    "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression() \n",
    "results = cross_val_score(model, X, Y, cv=kfold) \n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithm Performance Metrics\n",
    "\n",
    "Classification metrics\n",
    "- Classification Accuracy\n",
    "- Logarithmic Loss\n",
    "- Area Under ROC Curve \n",
    "- Confusion Matrix\n",
    "- Classification Report\n",
    "\n",
    "Regression metrics\n",
    "- Mean Absolute Error\n",
    "- Mean Squared Error\n",
    "- $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification accuracy\n",
    "\n",
    "- Classification accuracy is the number of correct predictions made as a ratio of all predictions made. \n",
    "- This is the most common evaluation metric for classification problems, it is also the most misused. \n",
    "- It is really only suitable when there are an equal number of observations in each class (which is rarely the case) and that all predictions and prediction errors are equally important, which is often not the case. \n",
    "\n",
    "![](images/classification_accuracy.png)\n",
    "\n",
    "- This accuracy can be calculated based on a hold-out dataset not seen by the model during training, such as a validation or test dataset. \n",
    "- Classification accuracy or classification error is a proportion or a ratio. It describes the proportion of correct or incorrect predictions made by the model. \n",
    "- Each prediction is a binary decision that could be correct or incorrect. \n",
    "- Technically, this is called a Bernoulli trial, named for Jacob Bernoulli. \n",
    "- The proportions in a Bernoulli trial have a specific distribution called a binomial distribution. \n",
    "- With large sample sizes (more than 30), we can approximate the distribution with a Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:47.684189Z",
     "start_time": "2019-10-09T04:12:47.537055Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Clump Thickness'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-4eb53dd4f2f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: %.3f (%.3f)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 231\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[1;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    595\u001b[0m     \"\"\"\n\u001b[0;32m    596\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \"\"\"\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \"\"\"\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    263\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Clump Thickness'"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Accuracy \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = LogisticRegression() \n",
    "scoring = 'accuracy' \n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(\"Accuracy: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logarithmic loss\n",
    "\n",
    "- Logarithmic loss (or logloss) is a performance metric for evaluating the predictions of probabilities of membership to a given class. \n",
    "- The scalar probability between 0 and 1 can be seen as a measure of confidence for a prediction by an algorithm. \n",
    "- Predictions that are correct or incorrect are rewarded or punished proportionally to the confidence of the prediction.\n",
    "\n",
    "Also:\n",
    "- Log loss, also called logistic loss, logarithmic loss, or cross-entropy can be used as a measure for evaluating predicted probabilities. \n",
    "- Each predicted probability is compared to the actual class output value (0 or 1) and a score is calculated that penalizes the probability based on the distance from the expected value. \n",
    "- The penalty is logarithmic, offering a small score for small differences (0.1 or 0.2) and enormous score for a large difference (0.9 or 1.0). \n",
    "- A model with perfect skill has a log loss score of 0.0. \n",
    "- In order to summarize the skill of a model using log loss, the log loss is calculated for each predicted probability, and the average loss is reported. \n",
    "- In the binary classification case, the function takes a list of true outcome values and a list of probabilities as arguments and calculates the average log loss for the predictions. \n",
    "\n",
    "Thus:\n",
    "- Model skill is reported as the average log loss across the predictions in a test dataset.\n",
    "- As an average, we can expect that the score will be suitable with a balanced dataset and misleading when there is a large imbalance between the two classes in the test set. \n",
    "- This is because predicting 0 or small probabilities will result in a small loss. \n",
    "- We can demonstrate this by comparing the distribution of loss values when predicting different constant probabilities for a balanced and an imbalanced dataset. \n",
    "- First, the example below predicts values from 0.0 to 1.0 in 0.1 increments for a balanced dataset of 50 examples of class 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:47.869047Z",
     "start_time": "2019-10-09T04:12:47.690687Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Clump Thickness'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-536440f8a0d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'neg_log_loss'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Logloss: %.3f (%.3f)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 231\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[1;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    595\u001b[0m     \"\"\"\n\u001b[0;32m    596\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, clf, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \"\"\"\n\u001b[0;32m    125\u001b[0m         \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1652\u001b[0m                                                 self.solver == 'liblinear')))\n\u001b[0;32m   1653\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0movr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1654\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1655\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m             \u001b[0mdecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_predict_proba_lr\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[0mmulticlass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mhandled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnormalizing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mover\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         \"\"\"\n\u001b[1;32m--> 303\u001b[1;33m         \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m         \u001b[0mexpit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    263\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Clump Thickness'"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification LogLoss \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "filename = 'breast_cancer_data.csv' \n",
    "names = ['Row' , 'Clump Thickness' , 'Uniformity of Cell Size' , 'Uniformity of Cell Shape' , 'Marginal Adhesion' , 'Single Epithelial  Cell Size' , 'Bare Nuclei' , 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Target'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = LogisticRegression() \n",
    "scoring = 'neg_log_loss' \n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(\"Logloss: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiver operating characteristics-area under curve\n",
    "\n",
    "- Area under ROC Curve (or AUC for short) is a performance metric for binary classification problems. \n",
    "- The AUC represents a model’s ability to discriminate between positive and negative classes. \n",
    "- An area of 1.0 represents a model that made all predictions perfectly. \n",
    "- An area of 0.5 represents a model that is as good as random. \n",
    "- ROC can be broken down into sensitivity and specificity. \n",
    "- A binary classification problem is really a trade-off between sensitivity and specificity.\n",
    "\n",
    "![](images/roc-auc.png)\n",
    "\n",
    "- Sensitivity is the true positive rate, also called the recall. It is the number of instances from the positive (first) class that were actually predicted correctly.\n",
    "- Specificity is also called the true negative rate. It is the number of instances from the negative (second) class that were actually predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:48.059151Z",
     "start_time": "2019-10-09T04:12:47.872011Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.824 (0.041)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification ROC AUC \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = LogisticRegression() \n",
    "scoring = 'roc_auc' \n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "\n",
    "- The confusion matrix is a handy presentation of the accuracy of a model with two or more classes. \n",
    "- The table presents predictions on the x-axis and true outcomes on the y-axis. \n",
    "- The cells of the table are the number of predictions made by a machine learning algorithm. \n",
    "- For example, a machine learning algorithm can predict 0 or 1 and each prediction may actually have been a 0 or 1. \n",
    "- Predictions for 0 that were actually 0 appear in the cell for $prediction = 0$ and $actual = 0$, whereas predictions for 0 that were actually 1 appear in the cell for $prediction = 0$ and $actual = 1$.\n",
    "\n",
    "![](images/confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:48.099043Z",
     "start_time": "2019-10-09T04:12:48.062255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141  21]\n",
      " [ 41  51]]\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Confusion Matrix \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import confusion_matrix \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "test_size = 0.33\n",
    "seed = 7 \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression() \n",
    "model.fit(X_train, Y_train) \n",
    "predicted = model.predict(X_test) \n",
    "matrix = confusion_matrix(Y_test, predicted) \n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report\n",
    "\n",
    "- The scikit-learn library provides a convenience report when working on classification problems to give you a quick idea of the accuracy of a model using a number of measures. \n",
    "- The `classification_report()` function displays the precision, recall, F1-score and support for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:48.140659Z",
     "start_time": "2019-10-09T04:12:48.102167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.87      0.82       162\n",
      "         1.0       0.71      0.55      0.62        92\n",
      "\n",
      "    accuracy                           0.76       254\n",
      "   macro avg       0.74      0.71      0.72       254\n",
      "weighted avg       0.75      0.76      0.75       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Report \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import classification_report \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "test_size = 0.33 \n",
    "seed = 7 \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression() \n",
    "model.fit(X_train, Y_train) \n",
    "predicted = model.predict(X_test) \n",
    "report = classification_report(Y_test, predicted) \n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean absolute error\n",
    "\n",
    "- The Mean Absolute Error (or MAE) is the sum of the absolute differences between predictions and actual values. \n",
    "- It gives an idea of how wrong the predictions were. \n",
    "- The measure gives an idea of the magnitude of the error, but no idea of the direction (e.g. over or under predicting).\n",
    "\n",
    "<!-- ![](images/mae.png) -->\n",
    "![](images/mean_absolute_error.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:48.195928Z",
     "start_time": "2019-10-09T04:12:48.143823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -4.005 (2.084)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression MAE \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LinearRegression \n",
    "filename = 'housing.csv' \n",
    "names = ['CRIM' , 'ZN' , 'INDUS' , 'CHAS' , 'NOX' , 'RM' , 'AGE' , 'DIS' , 'RAD' , 'TAX' , 'PTRATIO' , 'B' , 'LSTAT' , 'MEDV' ]\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:13] \n",
    "Y = array[:,13] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = LinearRegression() \n",
    "scoring = 'neg_mean_absolute_error' \n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(\"MAE: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean squared error\n",
    "\n",
    "- The Mean Squared Error (or MSE) is much like the mean absolute error in that it provides a gross idea of the magnitude of error. \n",
    "- Taking the square root of the mean squared error converts the units back to the original units of the output variable and can be meaningful for description and presentation. This is called the Root Mean Squared Error (or RMSE).\n",
    "\n",
    "<!--![](images/mse.png)\n",
    "![](images/mse_itsl.png)-->\n",
    "\n",
    "![](images/root_mean_squared_error.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:48.251266Z",
     "start_time": "2019-10-09T04:12:48.201989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -34.705 (45.574)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression MSE \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LinearRegression \n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM' , 'ZN' , 'INDUS' , 'CHAS' , 'NOX' , 'RM' , 'AGE' , 'DIS' , 'RAD' , 'TAX' , 'PTRATIO' , 'B' , 'LSTAT' , 'MEDV' ]\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:13] \n",
    "Y = array[:,13] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = LinearRegression() \n",
    "scoring = 'neg_mean_squared_error' \n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(\"MSE: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-squared metric\n",
    "\n",
    "- The $R^2$ (or R Squared) metric provides an indication of the goodness of fit of a set of predictions to the actual values. \n",
    "- In statistical literature this measure is called the coefficient of determination. This is a value between 0 and 1 for no-fit and perfect fit respectively.\n",
    "\n",
    "![](images/00_residuals.png)\n",
    "![](images/01_mean_observed_data.png)\n",
    "![](images/02_total_sum_of_squares.png)\n",
    "![](images/03_explained_sum_of_squares.png)\n",
    "![](images/04_residual_sum_of_squares.png)\n",
    "![](images/05_coefficient_of_determination.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:48.301888Z",
     "start_time": "2019-10-09T04:12:48.254541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.203 (0.595)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression R^2 \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LinearRegression \n",
    "filename = 'housing.csv' \n",
    "names = ['CRIM' , 'ZN' , 'INDUS' , 'CHAS' , 'NOX' , 'RM' , 'AGE' , 'DIS' , 'RAD' , 'TAX' , 'PTRATIO' , 'B' , 'LSTAT' , 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:13] \n",
    "Y = array[:,13] \n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LinearRegression() \n",
    "scoring = 'r2' \n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(\"R^2: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot-Check Classification Algorithms\n",
    "\n",
    "Linear\n",
    "- Logistic Regression\n",
    "- Linear Discriminant Analysis\n",
    "\n",
    "\n",
    "Non-linear\n",
    "- k-Nearest Neighbors\n",
    "- Naive Bayes\n",
    "- Classification and Regression Trees\n",
    "- Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "- Logistic regression assumes a Gaussian distribution for the numeric input variables and can model binary classification problems.\n",
    "\n",
    "![](images/lr_yhat.png)\n",
    "![](images/lr_yhat_simplified.png)\n",
    "\n",
    "![](images/logistic_curve.png)\n",
    "![](images/sigmoid_function.png)\n",
    "\n",
    "![](images/logistic_regression.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:48.461900Z",
     "start_time": "2019-10-09T04:12:48.306492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7695146958304853\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Classification \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "model = LogisticRegression() \n",
    "results = cross_val_score(model, X, Y, cv=kfold) \n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear discriminant analysis\n",
    "\n",
    "- Linear Discriminant Analysis or LDA is a statistical technique for binary and multiclass classification. \n",
    "- It assumes a Gaussian distribution for the numerical input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:48.539893Z",
     "start_time": "2019-10-09T04:12:48.464926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773462064251538\n"
     ]
    }
   ],
   "source": [
    "# LDA Classification \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8]\n",
    "Y = array[:,8] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = LinearDiscriminantAnalysis() \n",
    "results = cross_val_score(model, X, Y, cv=kfold) \n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors\n",
    "\n",
    "- The k-Nearest Neighbors algorithm (or KNN) uses a distance metric to find the $k$ most similar instances in the training data for a new instance and takes the mean outcome of the neighbors as the prediction.\n",
    "\n",
    "This can be simplified as steps:\n",
    "\n",
    "1. Calculate Euclidean distance\n",
    "1. Get neighbors\n",
    "1. Make predictions\n",
    "\n",
    "Euclidean distance: \n",
    "- The first step needed is to calculate the distance between two rows in a dataset. \n",
    "- Rows of data are mostly made up of numbers and an easy way to calculate the distance between two rows or vectors of numbers is to draw a straight line. \n",
    "- This makes sense in 2D or 3D and scales nicely to higher dimensions. \n",
    "- We can calculate the straight line distance between two vectors using the Euclidean distance measure. \n",
    "- It is calculated as the square root of the sum of the squared differences between the two vectors.\n",
    "\n",
    "![](images/knn_distance.png)\n",
    "\n",
    "Get neighbors:\n",
    "- Neighbors for a new piece of data in the dataset are the $k$ closest instances, as defined by our distance measure. \n",
    "- To locate the neighbors for a new piece of data within a dataset we must first calculate the distance between each record in the dataset to the new piece of data. \n",
    "- We can do this using our distance function above. \n",
    "- Once distances are calculated, we must sort all of the records in the training dataset by their distance to the new data. \n",
    "- We can then select the top $k$ to return as the most similar neighbors.\n",
    "\n",
    "Make predictions:\n",
    "- The most similar neighbors collected from the training dataset can be used to make predictions. \n",
    "- In the case of classification, we can return the most represented class among the neighbors. \n",
    "- We can achieve this by getting the maximum on the list of output values from the neighbors. \n",
    "- Given a list of class values observed in the neighbors, the getting the maximum takes a set of unique class values and calls the count on the list of class values for each class value in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:48.656798Z",
     "start_time": "2019-10-09T04:12:48.542999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7265550239234451\n"
     ]
    }
   ],
   "source": [
    "# KNN Classification\n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = KNeighborsClassifier() \n",
    "results = cross_val_score(model, X, Y, cv=kfold) \n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes \n",
    "\n",
    "- Naive Bayes calculates the probability of each class and the conditional probability of each class given each input value. \n",
    "- These probabilities are estimated for new data and multiplied together, assuming that they are all independent (a simple or naive assumption). \n",
    "- When working with real-valued data, a Gaussian distribution is assumed to easily estimate the probabilities for input variables using the Gaussian Probability Density Function.\n",
    "\n",
    "Also: \n",
    "- Bayes’ Theorem provides a way that we can calculate the probability of a piece of data belonging to a given class, given our prior knowledge.\n",
    "\n",
    "![](images/nb_bayes_theorem.png)\n",
    "\n",
    "- Where $P(class|data)$ is the probability of class given the provided data. \n",
    "- Naive Bayes is a classification algorithm for binary (two-class) and multiclass classification problems. \n",
    "- It is called Naive Bayes or idiot Bayes because the calculations of the probabilities for each class are simplified to make their calculations tractable. \n",
    "- Rather than attempting to calculate the probabilities of each attribute value, they are assumed to be conditionally independent given the class value. \n",
    "- This is a very strong assumption that is most unlikely in real data such that the attributes do not interact. \n",
    "- Nevertheless, the approach performs surprisingly well on data where this assumption does not hold.\n",
    "\n",
    "![](images/nb_mean.png)\n",
    "![](images/nb_standard_deviation.png)\n",
    "![](images/nb_gaussian_probability.png)\n",
    "![](images/nb_class_probability.png)\n",
    "![](images/nb_class_0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:48.710787Z",
     "start_time": "2019-10-09T04:12:48.659882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7551777170198223\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes Classification \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class' ] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = GaussianNB() \n",
    "results = cross_val_score(model, X, Y, cv=kfold) \n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and regression trees\n",
    "\n",
    "- Classification and Regression Trees (CART or just decision trees) construct a binary tree from the training data. \n",
    "- Split points are chosen greedily by evaluating each attribute and each value of each attribute in the training data in order to minimize a cost function (like the Gini index).\n",
    "\n",
    "Note:\n",
    "- For classification, the Gini cost function is used which provides an indication of how pure the nodes are, where node purity refers to how mixed the training data assigned to each node is.\n",
    "\n",
    "Creating a split involves three parts:\n",
    "\n",
    "1. Calculate the Gini score\n",
    "1. Split a dataset\n",
    "1. Evaluate all splits\n",
    "\n",
    "Calculate the Gini score:\n",
    "- The Gini index is the name of the cost function used to evaluate splits in the dataset. \n",
    "- A split in the dataset involves one input attribute and one value for that attribute. \n",
    "- It can be used to divide training patterns into two groups of rows. \n",
    "- A Gini score gives an idea of how good a split is by how mixed the classes are in the two groups created by the split. \n",
    "- A perfect separation results in a Gini score of 0, whereas the worst case split that results in 50/50 classes in each group results in a Gini score of 0.5 (for a 2 class problem).\n",
    "\n",
    "![](images/gini_index_proportion.png)\n",
    "![](images/gini_index_child_node.png)\n",
    "![](images/gini_index_group.png)\n",
    "\n",
    "Split a dataset:\n",
    "- Splitting a dataset means separating a dataset into two lists of rows given the index of an attribute and a split value for that attribute. \n",
    "- Once we have the two groups, we can then use our Gini score above to evaluate the cost of the split. \n",
    "- Splitting a dataset involves iterating over each row, checking if the attribute value is below or above the split value and assigning it to the left or right group respectively.\n",
    "\n",
    "Evaluate all splits:\n",
    "- Given a dataset, we must check every value on each attribute as a candidate split, evaluate the cost of the split and find the best possible split we could make. Once the best split is found, we can use it as a node in our decision tree.\n",
    "\n",
    "Note: **This is an exhaustive and greedy algorithm.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:48.800836Z",
     "start_time": "2019-10-09T04:12:48.713957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6990772385509227\n"
     ]
    }
   ],
   "source": [
    "# CART Classification \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = DecisionTreeClassifier() \n",
    "results = cross_val_score(model, X, Y, cv=kfold) \n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machines\n",
    "\n",
    "- Support Vector Machines (or SVM) seek a line that best separates two classes. \n",
    "- Those data instances that are closest to the line that best separates the classes are called support vectors and influence where the line is placed. \n",
    "- SVM has been extended to support multiple classes. \n",
    "- Of particular importance is the use of different kernel functions via the kernel parameter. \n",
    "- A powerful Radial Basis Function is used by default.\n",
    "\n",
    "![](images/svm_itsl.png)\n",
    "![](images/svm_support_vectors_01.png)\n",
    "![](images/svm_support_vectors_02.png)\n",
    "![](images/svm_polynomial.png)\n",
    "\n",
    "C is a nonnegative tuning parameter:\n",
    "\n",
    "![](images/svm_c_tuning_parameter.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:49.296383Z",
     "start_time": "2019-10-09T04:12:48.803931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6510252904989747\n"
     ]
    }
   ],
   "source": [
    "# SVM Classification \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC \n",
    "filename = 'pima-indians-diabetes.data.csv' \n",
    "names = ['preg' , 'plas' , 'pres' , 'skin' , 'test' , 'mass' , 'pedi' , 'age' , 'class'] \n",
    "dataframe = read_csv(filename, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:8] \n",
    "Y = array[:,8] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = SVC() \n",
    "results = cross_val_score(model, X, Y, cv=kfold) \n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot-Check Regression Algorithms\n",
    "\n",
    "Linear \n",
    "- Linear Regression\n",
    "- Ridge Regression\n",
    "- LASSO Linear Regression\n",
    "- Elastic Net Regression\n",
    "\n",
    "Nonlinear \n",
    "- k-Nearest Neighbors\n",
    "- Classification and Regression Trees\n",
    "- Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression \n",
    "\n",
    "- Linear regression assumes that the input variables have a Gaussian distribution. \n",
    "- It is also assumed that input variables are relevant to the output variable and that they are not highly correlated with each other (a problem called collinearity).\n",
    "\n",
    "![](images/simple_linear_regression.png)\n",
    "![](images/simple_linear_regression_mean.png)\n",
    "![](images/simple_linear_regression_variance.png)\n",
    "![](images/simple_linear_regression_covariance.png)\n",
    "![](images/simple_linear_regression_b1.png)\n",
    "![](images/simple_linear_regression_b1_2.png)\n",
    "![](images/simple_linear_regression_b0.png)\n",
    "\n",
    "![](images/simple_linear_regression_actual.png)\n",
    "![](images/simple_linear_regression_predicted.png)\n",
    "\n",
    "<!--![](images/simple_linear_regression_coefficients.png)-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:49.341157Z",
     "start_time": "2019-10-09T04:12:49.299407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.70525594452488\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LinearRegression \n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM' , 'ZN' , 'INDUS' , 'CHAS' , 'NOX' , 'RM' , 'AGE' , 'DIS' , 'RAD' , 'TAX' , 'PTRATIO' , 'B' , 'LSTAT' , 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:13] \n",
    "Y = array[:,13] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = LinearRegression() \n",
    "scoring = 'neg_mean_squared_error' \n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression\n",
    "\n",
    "- Ridge regression is an extension of linear regression where the loss function is modified to minimize the complexity of the model measured as the sum squared value of the coefficient values (also called the $L^2$-norm).\n",
    "\n",
    "Also:\n",
    "- The length of the vector is always a positive number, except for a vector of all zero values.\n",
    "- It is calculated using some measure that summarizes the distance of the vector from the origin of the vector space. \n",
    "- For example, the origin of a vector space for a vector with 3 elements is (0, 0, 0).\n",
    "\n",
    "Then:\n",
    "- The length of a vector can be calculated using the $L^2$ norm, where the $2$ is a superscript of the $L$. \n",
    "- The notation for the $L^2$ norm of a vector is $||v||_2$ where $2$ is a subscript.\n",
    "\n",
    "![](images/l2_norm.png)\n",
    "\n",
    "- The $L^2$ norm calculates the distance of the vector coordinate from the origin of the vector space. \n",
    "- As such, it is also known as the Euclidean norm as it is calculated as the Euclidean distance from the origin. \n",
    "- The result is a positive distance value. \n",
    "- The $L^2$ norm is calculated as the square root of the sum of the squared vector values.\n",
    "\n",
    "![](images/l2_vector.png)\n",
    "\n",
    "Note: The $L^2$ norm that is calculated as the square root of the sum of the squared vector values.\n",
    "\n",
    "**$\\lambda \\ge 0$ is a tuning parameter:**\n",
    "\n",
    "![](images/ridge_rss.png)\n",
    "![](images/ridge_lambda.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:49.401502Z",
     "start_time": "2019-10-09T04:12:49.344928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.07824620925939\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import Ridge \n",
    "filename = 'housing.csv' \n",
    "names = ['CRIM' , 'ZN' , 'INDUS' , 'CHAS' , 'NOX' , 'RM' , 'AGE' , 'DIS' , 'RAD' , 'TAX' , 'PTRATIO' , 'B' , 'LSTAT' , 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:13] \n",
    "Y = array[:,13] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = Ridge() \n",
    "scoring = 'neg_mean_squared_error' \n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO Regression\n",
    "\n",
    "- The Least Absolute Shrinkage and Selection Operator (or LASSO for short) is a modification of linear regression, like ridge regression, where the loss function is modified to minimize the complexity of the model measured as the sum absolute value of the coefficient values (also called the $L^1$-norm).\n",
    "\n",
    "Also:\n",
    "- The length of the vector is always a positive number, except for a vector of all zero values.\n",
    "- It is calculated using some measure that summarizes the distance of the vector from the origin of the vector space. \n",
    "- For example, the origin of a vector space for a vector with 3 elements is (0, 0, 0).\n",
    "\n",
    "Then:\n",
    "\n",
    "- The length of a vector can be calculated using the $L^1$ norm, where the $1$ is a superscript of the $L$. \n",
    "- The notation for the $L^1$ norm of a vector is $||v||_1$, where $1$ is a subscript. \n",
    "- As such, this length is sometimes called the taxicab norm or the Manhattan norm.\n",
    "\n",
    "![](images/l1_norm.png)\n",
    "\n",
    "- The $L^1$ norm is calculated as the sum of the absolute vector values, where the absolute value of a scalar uses the notation $|a1|$. \n",
    "- In effect, the norm is a calculation of the Manhattan distance from the origin of the vector space.\n",
    "\n",
    "![](images/l1_vector.png)\n",
    "\n",
    "- The $L^1$ norm is often used when fitting machine learning algorithms as a regularization method, for example, a method to keep the coefficients of the model small, and in turn, the model less complex.\n",
    "\n",
    "Note: The $L^1$ norm that is calculated as the sum of the absolute values of the vector.\n",
    "\n",
    "**Where $\\lambda \\ge 0$ is a tuning parameter:**\n",
    "\n",
    "![](images/ridge_rss.png)\n",
    "![](images/lasso_lambda.png)\n",
    "![](images/lasso_ridge_contours.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:49.456326Z",
     "start_time": "2019-10-09T04:12:49.405696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.46408458830232\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import Lasso \n",
    "filename = 'housing.csv' \n",
    "names = ['CRIM' , 'ZN' , 'INDUS' , 'CHAS' , 'NOX' , 'RM' , 'AGE' , 'DIS' , 'RAD' , 'TAX' , 'PTRATIO' , 'B' , 'LSTAT' , 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:13] \n",
    "Y = array[:,13]\n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = Lasso() \n",
    "scoring = 'neg_mean_squared_error' \n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet regression \n",
    "\n",
    "- ElasticNet is a form of regularization regression that combines the properties of both Ridge Regression and LASSO regression. \n",
    "- It seeks to minimize the complexity of the regression model (magnitude and number of regression coefficients) by penalizing the model using both the L2-norm (sum squared coefficient values) and the L1-norm (sum absolute coefficient values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:49.516802Z",
     "start_time": "2019-10-09T04:12:49.460120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-31.164573714249762\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet Regression \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import ElasticNet \n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM' , 'ZN' , 'INDUS' , 'CHAS' , 'NOX' , 'RM' , 'AGE' , 'DIS' , 'RAD' , 'TAX' , 'PTRATIO' , 'B' , 'LSTAT' , 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:13] \n",
    "Y = array[:,13] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = ElasticNet() \n",
    "scoring = 'neg_mean_squared_error' \n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors \n",
    "\n",
    "- The k-Nearest Neighbors algorithm (or KNN) locates the k most similar instances in the training dataset for a new data instance. \n",
    "- From the k neighbors, the mean or median output variable is taken as the prediction. Of note is the distance metric used (the metric argument). \n",
    "- The Minkowski distance is used by default, which is a generalization of both the Euclidean distance (used when all inputs have the same scale) and Manhattan distance (used when the scales of the input variables differ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:49.573486Z",
     "start_time": "2019-10-09T04:12:49.520415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-107.28683898039215\n"
     ]
    }
   ],
   "source": [
    "# KNN Regression \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM' , 'ZN' , 'INDUS' , 'CHAS' , 'NOX' , 'RM' , 'AGE' , 'DIS' , 'RAD' , 'TAX' , 'PTRATIO' , 'B' , 'LSTAT' , 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:13] \n",
    "Y = array[:,13] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = KNeighborsRegressor() \n",
    "scoring = 'neg_mean_squared_error' \n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and regression trees \n",
    "\n",
    "- Decision trees or the Classification and Regression Trees (CART as they are known) use the training data to select the best points to split the data in order to minimize a cost metric. \n",
    "- The default cost metric for regression decision trees is the mean squared error, specified in the `criterion` parameter.\n",
    "\n",
    "Note:\n",
    "- For regression, the cost function that is minimized to choose split points is the sum squared error across all training samples that fall within the rectangle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:49.703186Z",
     "start_time": "2019-10-09T04:12:49.580871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-32.478198039215684\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regression \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM' , 'ZN' , 'INDUS' , 'CHAS' , 'NOX' , 'RM' , 'AGE' , 'DIS' , 'RAD' , 'TAX' , 'PTRATIO' , 'B' , 'LSTAT' , 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:13] \n",
    "Y = array[:,13] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = DecisionTreeRegressor() \n",
    "scoring = 'neg_mean_squared_error' \n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "- Support Vector Machines (SVM) were developed for binary classification. \n",
    "- The technique has been extended for the prediction real-valued problems called Support Vector Regression (SVR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T04:12:49.988659Z",
     "start_time": "2019-10-09T04:12:49.707026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-91.04782433324428\n"
     ]
    }
   ],
   "source": [
    "# SVM Regression \n",
    "from pandas import read_csv \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.svm import SVR \n",
    "filename = 'housing.csv'\n",
    "names = ['CRIM' , 'ZN' , 'INDUS' , 'CHAS' , 'NOX' , 'RM' , 'AGE' , 'DIS' , 'RAD' , 'TAX' , 'PTRATIO' , 'B' , 'LSTAT' , 'MEDV']\n",
    "dataframe = read_csv(filename, delim_whitespace=True, names=names) \n",
    "array = dataframe.values \n",
    "X = array[:,0:13] \n",
    "Y = array[:,13] \n",
    "kfold = KFold(n_splits=10, random_state=7) \n",
    "model = SVR() \n",
    "scoring = 'neg_mean_squared_error' \n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring) \n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "458px",
    "left": "198px",
    "top": "110px",
    "width": "328px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
